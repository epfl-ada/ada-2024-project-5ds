{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON, CSV\n",
    "\n",
    "user_agent = \"Mus/1.0\"\n",
    "wiki_wiki = wikipediaapi.Wikipedia(user_agent=user_agent, language='en')\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\", agent=user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_films_by_year(year):\n",
    "    category_name = f\"Category:{year} films\"\n",
    "    category = wiki_wiki.page(category_name)\n",
    "\n",
    "    # Check if the category exists\n",
    "    if not category.exists():\n",
    "        print(f\"Category '{category_name}' does not exist.\")\n",
    "        return []\n",
    "\n",
    "    # Collect film titles from the category\n",
    "    films = [page.title for page_title, page in category.categorymembers.items()\n",
    "             if page.ns == wikipediaapi.Namespace.MAIN]\n",
    "    return films\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(page_title):\n",
    "    # Get the page\n",
    "    \n",
    "    wiki_wiki = wikipediaapi.Wikipedia(user_agent=user_agent, language='en')\n",
    "    page = wiki_wiki.page(page_title)\n",
    "    \n",
    "    if not page.exists():\n",
    "        print(f\"Page '{page_title}' does not exist.\")\n",
    "        return None\n",
    "    \n",
    "    # Get the page url\n",
    "    url = page.canonicalurl\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve page '{page_title}'.\")\n",
    "        return None\n",
    "    \n",
    "    # Parse the page content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    table = soup.find(\"table\", {\"class\": \"infobox\"})  # Find the infobox table\n",
    "    \n",
    "    informations = soup.find(\"a\", title=\"More information about this page\")\n",
    "    \n",
    "    page_info_url = \"https://en.wikipedia.org\"+informations.get(\"href\")\n",
    "    \n",
    "    page_info_response = requests.get(page_info_url)\n",
    "    \n",
    "    page_info_soup = BeautifulSoup(page_info_response.content, 'html.parser')\n",
    "    \n",
    "    # Find all <tr> tags\n",
    "    rows = page_info_soup.find_all('tr')\n",
    "\n",
    "    # Loop through each row to find the one with the desired structure\n",
    "    for row in rows:\n",
    "        # Find all <td> elements within the row\n",
    "        tds = row.find_all('td')\n",
    "        # Check if there are exactly two <td> elements and if one contains the desired text\n",
    "        if len(tds) == 2 and \"Wikidata item ID\" in tds[0].text:\n",
    "            # Found the desired row, process it as needed\n",
    "            wikidata_id = tds[1].text.strip()\n",
    "        elif len(tds) == 2 and \"Page ID\" in tds[0].text:\n",
    "            page_id = tds[1].text.strip()\n",
    "    \n",
    "    return wikidata_id, page_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikidata_info(wikidata_id, sparqlAgent):\n",
    "    \n",
    "    query = f\"\"\"\n",
    "      SELECT ?film ?filmLabel (MIN(?releaseDate) AS ?earliestReleaseDate) (MAX(?boxOffice) AS ?highestBoxOffice) ?runtime \n",
    "            (GROUP_CONCAT(DISTINCT ?languageLabel; separator=\", \") AS ?languages) \n",
    "            (GROUP_CONCAT(DISTINCT ?countryLabel; separator=\", \") AS ?countries) \n",
    "            (GROUP_CONCAT(DISTINCT ?genreLabel; separator=\", \") AS ?genres)\n",
    "            (GROUP_CONCAT(DISTINCT ?reviewScoreLabel; separator=\", \") AS ?reviewScores)\n",
    "            (GROUP_CONCAT(DISTINCT ?awardLabel; separator=\", \") AS ?awardsReceived)\n",
    "            (GROUP_CONCAT(DISTINCT ?nominatedAwardLabel; separator=\", \") AS ?awardsNominated)\n",
    "            ?capitalCost WHERE {{\n",
    "        BIND(wd:{wikidata_id} AS ?film)  # Using the specific Wikidata movie ID\n",
    "        \n",
    "        ?film wdt:P31 wd:Q11424;  # Instance of film\n",
    "              wdt:P577 ?releaseDate.\n",
    "        \n",
    "        OPTIONAL {{ ?film wdt:P2142 ?boxOffice. }}\n",
    "        OPTIONAL {{ ?film wdt:P2047 ?runtime. }}\n",
    "        OPTIONAL {{ ?film wdt:P364 ?language. ?language rdfs:label ?languageLabel. FILTER(LANG(?languageLabel) = \"en\") }}\n",
    "        OPTIONAL {{ ?film wdt:P495 ?country. ?country rdfs:label ?countryLabel. FILTER(LANG(?countryLabel) = \"en\") }}\n",
    "        OPTIONAL {{ ?film wdt:P136 ?genre. ?genre rdfs:label ?genreLabel. FILTER(LANG(?genreLabel) = \"en\") }}\n",
    "        OPTIONAL {{ ?film wdt:P444 ?reviewScoreLabel. }}\n",
    "        OPTIONAL {{ ?film wdt:P166 ?award. ?award rdfs:label ?awardLabel. FILTER(LANG(?awardLabel) = \"en\") }}\n",
    "        OPTIONAL {{ ?film wdt:P1411 ?nominatedAward. ?nominatedAward rdfs:label ?nominatedAwardLabel. FILTER(LANG(?nominatedAwardLabel) = \"en\") }}\n",
    "        OPTIONAL {{ ?film wdt:P2130 ?capitalCost. }}\n",
    "\n",
    "        SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
    "      }}\n",
    "      GROUP BY ?film ?filmLabel ?runtime ?capitalCost\n",
    "      \"\"\"\n",
    "    \n",
    "    sparqlAgent.setQuery(query)\n",
    "    sparqlAgent.setReturnFormat(JSON)\n",
    "    results = sparqlAgent.query().convert()\n",
    "    \n",
    "    return results['results']['bindings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_film_info(film_title):\n",
    "    wikidata_id, page_id = get_id(film_title)\n",
    "    if wikidata_id is None:\n",
    "        return None\n",
    "    \n",
    "    film_info = get_wikidata_info(wikidata_id, sparql)\n",
    "    \n",
    "    info = {}\n",
    "    \n",
    "    for film in film_info:\n",
    "        \n",
    "        info['page_id'] = page_id\n",
    "        info['wikidata_id'] = wikidata_id\n",
    "        info['film'] = film['filmLabel']['value']\n",
    "        info['release_date'] = film['earliestReleaseDate']['value']\n",
    "        info['box_office'] = film['highestBoxOffice']['value'] if 'highestBoxOffice' in film else None\n",
    "        info['runtime'] = film['runtime']['value'] if 'runtime' in film else None\n",
    "        info['languages'] = film['languages']['value'] if 'languages' in film else None\n",
    "        info['countries'] = film['countries']['value'] if 'countries' in film else None\n",
    "        \n",
    "        \n",
    "        genres = film['genres']['value'] if 'genres' in film else None\n",
    "        genres = genres.split(\", \") if genres is not None else None\n",
    "        info['genres'] = [genre.replace(\"film\", \"\").strip() for genre in genres if len(genre.split()) <= 2 ]\n",
    "        \n",
    "        reviewScores = film['reviewScores']['value'] if 'reviewScores' in film else None\n",
    "        reviewScores = reviewScores.split(\", \") if reviewScores is not None else None\n",
    "        info['reviewScores'] = reviewScores\n",
    "        \n",
    "        reviewScoresAuthors = film['reviewScoreAuthors']['value'] if 'reviewScoreAuthors' in film else None\n",
    "        reviewScoresAuthors = reviewScoresAuthors.split(\", \") if reviewScoresAuthors is not None else None\n",
    "        info['reviewScoresAuthors'] = reviewScoresAuthors\n",
    "        \n",
    "        awardsReceived = film['awardsReceived']['value'] if 'awardsReceived' in film else None\n",
    "        awardsReceived = awardsReceived.split(\", \") if awardsReceived is not None else None\n",
    "        info['awardsReceived'] = awardsReceived\n",
    "        \n",
    "        awardsNominated = film['awardsNominated']['value'] if 'awardsNominated' in film else None\n",
    "        awardsNominated = awardsNominated.split(\", \") if awardsNominated is not None else None\n",
    "        info['awardsNominated'] = awardsNominated\n",
    "        \n",
    "        info['capitalCost'] = film['capitalCost']['value'] if 'capitalCost' in film else None\n",
    "\n",
    "        \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = get_film_info(\"The Godfather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikidata_id</th>\n",
       "      <th>film</th>\n",
       "      <th>release_date</th>\n",
       "      <th>box_office</th>\n",
       "      <th>runtime</th>\n",
       "      <th>languages</th>\n",
       "      <th>countries</th>\n",
       "      <th>genres</th>\n",
       "      <th>reviewScores</th>\n",
       "      <th>reviewScoresAuthors</th>\n",
       "      <th>awardsReceived</th>\n",
       "      <th>awardsNominated</th>\n",
       "      <th>capitalCost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2466773</th>\n",
       "      <td>Q47703</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972-03-15T00:00:00Z</td>\n",
       "      <td>250341816</td>\n",
       "      <td>175</td>\n",
       "      <td>Italian, English</td>\n",
       "      <td>Italy, United States of America</td>\n",
       "      <td>[epic, crime, drama, thriller, gangster, histo...</td>\n",
       "      <td>[100/100, 97%, 9.4/10]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Academy Award for Best Writing, Adapted Scree...</td>\n",
       "      <td>[Academy Award for Best Picture, Academy Award...</td>\n",
       "      <td>6000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wikidata_id           film          release_date box_office runtime  \\\n",
       "page_id                                                                       \n",
       "2466773      Q47703  The Godfather  1972-03-15T00:00:00Z  250341816     175   \n",
       "\n",
       "                languages                        countries  \\\n",
       "page_id                                                      \n",
       "2466773  Italian, English  Italy, United States of America   \n",
       "\n",
       "                                                    genres  \\\n",
       "page_id                                                      \n",
       "2466773  [epic, crime, drama, thriller, gangster, histo...   \n",
       "\n",
       "                   reviewScores reviewScoresAuthors  \\\n",
       "page_id                                               \n",
       "2466773  [100/100, 97%, 9.4/10]                None   \n",
       "\n",
       "                                            awardsReceived  \\\n",
       "page_id                                                      \n",
       "2466773  [Academy Award for Best Writing, Adapted Scree...   \n",
       "\n",
       "                                           awardsNominated capitalCost  \n",
       "page_id                                                                 \n",
       "2466773  [Academy Award for Best Picture, Academy Award...     6000000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(infos, orient='index').T\n",
    "df.set_index('page_id', inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013: Retrieved 3325 films.\n",
      "2014: Retrieved 3478 films.\n",
      "2015: Retrieved 3504 films.\n",
      "2016: Retrieved 3447 films.\n",
      "2017: Retrieved 3310 films.\n",
      "2018: Retrieved 3253 films.\n",
      "2019: Retrieved 3317 films.\n",
      "2020: Retrieved 2268 films.\n",
      "2021: Retrieved 2580 films.\n",
      "2022: Retrieved 2887 films.\n",
      "2023: Retrieved 2827 films.\n",
      "2024: Retrieved 2190 films.\n"
     ]
    }
   ],
   "source": [
    "films_since_2013 = {}\n",
    "\n",
    "for year in range(2013, 2025):  # Adjust end year as needed\n",
    "    films = get_films_by_year(year)\n",
    "    films_since_2013[year] = films\n",
    "    print(f\"{year}: Retrieved {len(films)} films.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2013 films:\n",
      "processed film +1 (film).\n",
      "processed film 1 (2013 film).\n",
      "processed film The 1 Up Fever.\n",
      "processed film 1,001 Apples.\n",
      "processed film 2 Autumns, 3 Winters.\n",
      "processed film 2 Guns.\n",
      "processed film 3 Days in Havana.\n",
      "processed film 3 Dots.\n",
      "processed film 3 Geezers!.\n",
      "processed film 3 Peas in a Pod.\n",
      "processed film 3G (film).\n",
      "processed film 3G Love.\n",
      "processed film 3x3D.\n",
      "processed film 5 Sundarikal.\n",
      "processed film 6 (film).\n",
      "processed film 6-5=2.\n",
      "processed film 7 Assassins.\n",
      "processed film 7 Pecados Rurais.\n",
      "processed film 7th Floor.\n",
      "processed film 8-pallo.\n",
      "processed film 9 Full Moons.\n",
      "processed film 9 Meter.\n",
      "processed film 9 Month Stretch.\n",
      "processed film 10 Minutes (2013 film).\n",
      "processed film 10 Rules for Sleeping Around.\n",
      "processed film 10%: What Makes a Hero?.\n",
      "processed film 10,000 Hours (film).\n",
      "processed film 10,000 Nights Nowhere.\n",
      "processed film 10:30 am Local Call.\n",
      "processed film 11 A.M. (film).\n",
      "processed film 11.6.\n",
      "processed film 12 O'Clock Boys.\n",
      "processed film 12 Rounds 2: Reloaded.\n",
      "processed film 12 Years a Slave (film).\n",
      "processed film 12-12-12.\n",
      "processed film 13/13/13.\n",
      "processed film 13 Eerie.\n",
      "processed film 15 Years and One Day.\n",
      "processed film 20 Feet Below: The Darkness Descending.\n",
      "processed film 20 Feet from Stardom.\n",
      "processed film 21 & Over (film).\n",
      "processed film 21 Ways to Ruin a Marriage.\n",
      "processed film 23 Blast.\n",
      "processed film 24 Exposures.\n",
      "processed film 30 Nights of Paranormal Activity with the Devil Inside the Girl with the Dragon Tattoo.\n",
      "processed film 36 Saints.\n",
      "processed film 42 (film).\n",
      "processed film 47 Ronin (2013 film).\n",
      "processed film 50 Children: The Rescue Mission of Mr. and Mrs. Kraus.\n",
      "processed film 52 Tuesdays.\n",
      "processed film 72 Miles.\n",
      "processed film 72 Model.\n",
      "processed film 99%: The Occupy Wall Street Collaborative Film.\n",
      "processed film 100 Days (2013 film).\n",
      "processed film 101 Chodyangal.\n",
      "processed film 200 Cartas.\n",
      "processed film 475 (film).\n",
      "processed film 475: Break the Silence.\n",
      "processed film 1000 Abaddalu.\n",
      "processed film 1939 Battle of Westerplatte.\n",
      "processed film 1982 (2013 film).\n",
      "processed film 3096 Days.\n",
      "processed film A Lan Zayar 2.\n",
      "processed film A Mike Sar.\n",
      "processed film A.C.O.D..\n",
      "processed film The A.R.K. Report.\n",
      "processed film Aadhalal Kadhal Seiveer.\n",
      "processed film Aadu Magaadra Bujji.\n",
      "processed film Aajcha Divas Majha.\n",
      "processed film Aandava Perumal.\n",
      "processed film Aane Pataaki.\n",
      "processed film Aaru Sundarimaarude Katha.\n",
      "processed film Aashiqui 2.\n",
      "processed film Aatma (2013 film).\n",
      "processed film Aattakatha (2013 film).\n",
      "processed film Abbai Class Ammai Mass.\n",
      "processed film ABCD: American-Born Confused Desi (2013 film).\n",
      "processed film ABCD: Any Body Can Dance.\n",
      "processed film Abhi Tou Main Jawan Hoon.\n",
      "processed film Abhinikmana.\n",
      "processed film Abhiyum Njanum.\n",
      "processed film Abner, the Invisible Dog.\n",
      "processed film Abo So.\n",
      "processed film Aborto.\n",
      "processed film About a Wife, a Dream and Another....\n",
      "processed film About Time (2013 film).\n",
      "processed film Absolute Deception.\n",
      "processed film Abuse of Weakness.\n",
      "processed film Accident (2013 film).\n",
      "processed film An Accidental Soldier.\n",
      "processed film Action 3D.\n",
      "processed film Ada Apa Dengan Rina.\n",
      "processed film Adda (2013 film).\n",
      "processed film Adieu Paris.\n",
      "processed film Adiós Carmen.\n",
      "processed film Adjust Your Tracking.\n",
      "processed film Admission (film).\n",
      "processed film Adolf Hitler: The Greatest Story Never Told.\n",
      "processed film Adoration (2013 film).\n",
      "processed film Adult World.\n",
      "processed film Advaitha (film).\n",
      "processed film An Adventure in Space and Time.\n",
      "processed film Adventures in the Sin Bin.\n",
      "processed film The Adventures of Sinbad (film).\n",
      "processed film Adventures of the Penguin King.\n",
      "processed film AE: Apocalypse Earth.\n",
      "processed film Afflicted (film).\n",
      "processed film African Independence.\n",
      "processed film After Earth.\n",
      "processed film After the Dark.\n",
      "processed film After Tiller.\n",
      "processed film Aftermath (2013 film).\n",
      "processed film Afternoon Delight (film).\n",
      "processed film Against the Wild.\n",
      "processed film Age 17.\n",
      "processed film Age of Dinosaurs.\n",
      "processed film Age of Panic.\n",
      "processed film Age of Uprising: The Legend of Michael Kohlhaas.\n",
      "processed film Agent Carter (film).\n",
      "processed film Ah Boys to Men 2.\n",
      "processed film Ai Weiwei: The Fake Case.\n",
      "processed film Ain't Them Bodies Saints.\n",
      "processed film Aina (2013 film).\n",
      "processed film Ainthu Ainthu Ainthu.\n",
      "processed film Akaash Vani.\n",
      "processed film Akka Pakka.\n",
      "processed film Akte Grüninger.\n",
      "processed film Alan Partridge: Alpha Papa.\n",
      "processed film Alan Poza.\n",
      "processed film Alcan Highway (film).\n",
      "processed film Aleksandr's Price.\n",
      "processed film Alex Pandian.\n",
      "processed film Alfie (2013 film).\n",
      "processed film Alfredo S. Lim (The Untold Story).\n",
      "processed film Algonquin (film).\n",
      "processed film Alias (2013 film).\n",
      "processed film Alias Janaki.\n",
      "processed film Alice in Chains: AIC 23.\n",
      "processed film Alice Walker: Beauty in Truth.\n",
      "processed film Alien Boy: The Life and Death of James Chasse.\n",
      "processed film Alik Sukh.\n",
      "processed film All Alone (film).\n",
      "processed film All Cheerleaders Die.\n",
      "processed film All for Two.\n",
      "processed film All Hallows' Eve (2013 film).\n",
      "processed film All I Want Is Everything (film).\n",
      "processed film All in All Azhagu Raja.\n",
      "processed film All Is Bright.\n",
      "processed film All Is Lost.\n",
      "processed film All of Me (2013 film).\n",
      "processed film All Stars (2013 film).\n",
      "processed film All That We Make.\n",
      "processed film All the Women.\n",
      "processed film All the Wrong Reasons (film).\n",
      "processed film All Things to All Men (film).\n",
      "processed film Almost Human (2013 film).\n",
      "processed film Alone for Christmas.\n",
      "processed film Alone yet Not Alone.\n",
      "processed film Alpha Girls.\n",
      "processed film Alt (film).\n",
      "processed film Altered Minds.\n",
      "processed film Amai Muchi.\n",
      "processed film Amar Bodyguard.\n",
      "processed film Amazing (film).\n",
      "processed film Amazing Azerbaijan.\n",
      "processed film The Amazing Catfish.\n",
      "processed film Amazonia (film).\n",
      "processed film Ambara.\n",
      "processed film Ambassada.\n",
      "processed film Ambushed (2013 film).\n",
      "processed film Ameerin Aadhi-Bhagavan.\n",
      "processed film Amen (2013 film).\n",
      "processed film American Arab (film).\n",
      "processed film American Dreams in China.\n",
      "processed film An American Girl: Saige Paints the Sky.\n",
      "processed film American Hustle.\n",
      "processed film An American in Madras.\n",
      "processed film American Milkshake.\n",
      "processed film American Promise (film).\n",
      "processed film American Revolutionary: The Evolution of Grace Lee Boggs.\n",
      "processed film American Vagabond.\n",
      "processed film Ami Aaj Nasto Hoye Jai.\n",
      "processed film Ami Aar Amar Girlfriends.\n",
      "processed film Amiche da morire.\n",
      "processed film The Amityville Asylum.\n",
      "processed film Among the Dust of Thieves.\n",
      "processed film Amsterdam (2013 film).\n",
      "processed film Ana Arabia.\n",
      "processed film Anchorman 2: The Legend Continues.\n",
      "processed film And Now a Word from Our Sponsor.\n",
      "processed film And We Love Life.\n",
      "processed film Andhar Bahar.\n",
      "processed film The Anderssons Hit the Road.\n",
      "processed film Andre Gregory: Before and After Dinner.\n",
      "processed film Angarki (2013 film).\n",
      "processed film Angel Home.\n",
      "processed film Angel Warriors.\n",
      "processed film Angélique (film).\n",
      "processed film Angulimala (2013 film).\n",
      "processed film Anima State.\n",
      "processed film The Animal Project.\n",
      "processed film Animosity (film).\n",
      "processed film Anina (film).\n",
      "processed film Anita e Garibaldi.\n",
      "processed film Anita: Speaking Truth to Power.\n",
      "processed film Anithya.\n",
      "processed film Anjuman (2013 film).\n",
      "processed film Ankhon Dekhi.\n",
      "processed film Ankur Arora Murder Case.\n",
      "processed film The Anna Nicole Story.\n",
      "processed film Annakodi.\n",
      "processed film Annayum Rasoolum.\n",
      "processed film Annum Innum Ennum.\n",
      "processed film Another House.\n",
      "processed film Another Life (2013 film).\n",
      "processed film Another Me (2013 film).\n",
      "processed film Another Promise.\n",
      "processed film Ant Story.\n",
      "processed film Antar (film).\n",
      "processed film Antarctica: A Year on Ice.\n",
      "processed film Anthaka Mundu Aa Tarvatha.\n",
      "processed film Anti Gas Skin.\n",
      "processed film Antisocial (film).\n",
      "processed film Anumati (film).\n",
      "processed film Anwar Ka Ajab Kissa.\n",
      "processed film Anything Is Possible (film).\n",
      "processed film Apio verde.\n",
      "processed film An Apology to Elephants.\n",
      "processed film App (film).\n",
      "processed film Apparitional (film).\n",
      "processed film Appayya (film).\n",
      "processed film Apple Penne.\n",
      "processed film Approaching Midnight.\n",
      "processed film Apur Panchali.\n",
      "processed film Aquadro.\n",
      "processed film Aravind 2.\n",
      "processed film L'arbitro (2013 film).\n",
      "processed film Are Avaaj Konacha.\n",
      "processed film Are We OK?.\n",
      "processed film Are You Here.\n",
      "processed film Arena (2013 film).\n",
      "processed film Arikil Oraal.\n",
      "processed film Arinzo.\n",
      "processed film Arjun: Kalimpong E Sitaharan.\n",
      "processed film Armaan (2013 film).\n",
      "processed film Armistice (film).\n",
      "processed film The Armstrong Lie.\n",
      "processed film Around the Block (film).\n",
      "processed film Aroused (film).\n",
      "processed film Arrambam.\n",
      "processed film Arrêtez-moi.\n",
      "processed film Arrows of the Thunder Dragon.\n",
      "processed film The Art of Happiness (film).\n",
      "processed film The Art of the Steal (2013 film).\n",
      "processed film Artémis, cœur d'artichaut.\n",
      "processed film Artist (film).\n",
      "processed film Aruvu Rezuru: Kikaijikake no Yōseitachi.\n",
      "processed film Arwad (film).\n",
      "processed film Arya Surya.\n",
      "processed film As Cool as I Am (film).\n",
      "processed film As I Lay Dying (film).\n",
      "processed film As Night Falls.\n",
      "processed film As U Like.\n",
      "processed film Asa Mee Ashi Tee.\n",
      "processed film Aschenbrödel und der gestiefelte Kater.\n",
      "processed film Ashchorjyo Prodeep.\n",
      "processed film Ask This of Rikyu.\n",
      "processed film Asphalt Watches.\n",
      "processed film Ass Backwards.\n",
      "processed film Assault on Wall Street.\n",
      "processed film Assumed Killer.\n",
      "processed film Astu.\n",
      "processed film ¡Asu mare!.\n",
      "processed film At Middleton.\n",
      "processed film Até que a Sbórnia nos Separe.\n",
      "processed film Até que a Sorte nos Separe 2.\n",
      "processed film Athadu Aame O Scooter.\n",
      "processed film Atlantic Rim (film).\n",
      "processed film The Attacks of 26/11.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m films:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m film \u001b[38;5;129;01min\u001b[39;00m films:\n\u001b[1;32m----> 6\u001b[0m     film_info \u001b[38;5;241m=\u001b[39m get_film_info(film)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m film_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m         film_dict[film] \u001b[38;5;241m=\u001b[39m film_info\n",
      "Cell \u001b[1;32mIn[118], line 6\u001b[0m, in \u001b[0;36mget_film_info\u001b[1;34m(film_title)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wikidata_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m film_info \u001b[38;5;241m=\u001b[39m get_wikidata_info(wikidata_id, sparql)\n\u001b[0;32m      8\u001b[0m info \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m film \u001b[38;5;129;01min\u001b[39;00m film_info:\n",
      "Cell \u001b[1;32mIn[116], line 26\u001b[0m, in \u001b[0;36mget_wikidata_info\u001b[1;34m(wikidata_id, sparqlAgent)\u001b[0m\n\u001b[0;32m     24\u001b[0m sparqlAgent\u001b[38;5;241m.\u001b[39msetQuery(query)\n\u001b[0;32m     25\u001b[0m sparqlAgent\u001b[38;5;241m.\u001b[39msetReturnFormat(JSON)\n\u001b[1;32m---> 26\u001b[0m results \u001b[38;5;241m=\u001b[39m sparqlAgent\u001b[38;5;241m.\u001b[39mquery()\u001b[38;5;241m.\u001b[39mconvert()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbindings\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\site-packages\\SPARQLWrapper\\Wrapper.py:960\u001b[0m, in \u001b[0;36mSPARQLWrapper.query\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryResult\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    943\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;124;03m    Execute the query.\u001b[39;00m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03m    Exceptions can be raised if either the URI is wrong or the HTTP sends back an error (this is also the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    958\u001b[0m \u001b[38;5;124;03m    :rtype: :class:`QueryResult` instance\u001b[39;00m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m QueryResult(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query())\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\site-packages\\SPARQLWrapper\\Wrapper.py:926\u001b[0m, in \u001b[0;36mSPARQLWrapper._query\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    924\u001b[0m         response \u001b[38;5;241m=\u001b[39m urlopener(request, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout)\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 926\u001b[0m         response \u001b[38;5;241m=\u001b[39m urlopener(request)\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturnFormat\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    537\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPSConnection, req,\n\u001b[0;32m   1392\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context, check_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_hostname)\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\urllib\\request.py:1317\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m URLError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno host given\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;66;03m# will parse host:port\u001b[39;00m\n\u001b[1;32m-> 1317\u001b[0m h \u001b[38;5;241m=\u001b[39m http_class(host, timeout\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhttp_conn_args)\n\u001b[0;32m   1318\u001b[0m h\u001b[38;5;241m.\u001b[39mset_debuglevel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_debuglevel)\n\u001b[0;32m   1320\u001b[0m headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(req\u001b[38;5;241m.\u001b[39munredirected_hdrs)\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\http\\client.py:1442\u001b[0m, in \u001b[0;36mHTTPSConnection.__init__\u001b[1;34m(self, host, port, key_file, cert_file, timeout, source_address, context, check_hostname, blocksize)\u001b[0m\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcert_file \u001b[38;5;241m=\u001b[39m cert_file\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1442\u001b[0m     context \u001b[38;5;241m=\u001b[39m ssl\u001b[38;5;241m.\u001b[39m_create_default_https_context()\n\u001b[0;32m   1443\u001b[0m     \u001b[38;5;66;03m# send ALPN extension to indicate HTTP/1.1 protocol\u001b[39;00m\n\u001b[0;32m   1444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http_vsn \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m11\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\ssl.py:775\u001b[0m, in \u001b[0;36mcreate_default_context\u001b[1;34m(purpose, cafile, capath, cadata)\u001b[0m\n\u001b[0;32m    770\u001b[0m     context\u001b[38;5;241m.\u001b[39mload_verify_locations(cafile, capath, cadata)\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mverify_mode \u001b[38;5;241m!=\u001b[39m CERT_NONE:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;66;03m# no explicit cafile, capath or cadata but the verify mode is\u001b[39;00m\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;66;03m# CERT_OPTIONAL or CERT_REQUIRED. Let's try to load default system\u001b[39;00m\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;66;03m# root CA certificates for the given purpose. This may fail silently.\u001b[39;00m\n\u001b[1;32m--> 775\u001b[0m     context\u001b[38;5;241m.\u001b[39mload_default_certs(purpose)\n\u001b[0;32m    776\u001b[0m \u001b[38;5;66;03m# OpenSSL 1.1.1 keylog file\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(context, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeylog_filename\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\ssl.py:597\u001b[0m, in \u001b[0;36mSSLContext.load_default_certs\u001b[1;34m(self, purpose)\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m storename \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_windows_cert_stores:\n\u001b[0;32m    596\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_windows_store_certs(storename, purpose)\n\u001b[1;32m--> 597\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_default_verify_paths()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "film_dict = {}\n",
    "\n",
    "for year, films in films_since_2013.items():\n",
    "    print(f\"\\n{year} films:\")\n",
    "    for film in films:\n",
    "        film_info = get_film_info(film)\n",
    "        if film_info is not None:\n",
    "            film_dict[film] = film_info\n",
    "            print(f'processed film {film}.')\n",
    "        else:\n",
    "            print(f\"Failed to retrieve information for '{film}'.\")\n",
    "        \n",
    "        \n",
    "    print(f'Processed films for {year}.')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(film_dict, orient='index')\n",
    "df.to_csv('Films_2013_2019.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
