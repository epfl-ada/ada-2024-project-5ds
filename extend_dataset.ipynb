{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON, CSV\n",
    "\n",
    "user_agent = \"Mus/1.0\"\n",
    "wiki_wiki = wikipediaapi.Wikipedia(user_agent=user_agent, language='en')\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\", agent=user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_films_by_year(year):\n",
    "    category_name = f\"Category:{year} films\"\n",
    "    category = wiki_wiki.page(category_name)\n",
    "\n",
    "    # Check if the category exists\n",
    "    if not category.exists():\n",
    "        print(f\"Category '{category_name}' does not exist.\")\n",
    "        return []\n",
    "\n",
    "    # Collect film titles from the category\n",
    "    films = [page.title for page_title, page in category.categorymembers.items()\n",
    "             if page.ns == wikipediaapi.Namespace.MAIN]\n",
    "    return films\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(page_title):\n",
    "    # Get the page\n",
    "    \n",
    "    wiki_wiki = wikipediaapi.Wikipedia(user_agent=user_agent, language='en')\n",
    "    page = wiki_wiki.page(page_title)\n",
    "    \n",
    "    if not page.exists():\n",
    "        print(f\"Page '{page_title}' does not exist.\")\n",
    "        return None\n",
    "    \n",
    "    # Get the page url\n",
    "    url = page.canonicalurl\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve page '{page_title}'.\")\n",
    "        return None\n",
    "    \n",
    "    # Parse the page content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    table = soup.find(\"table\", {\"class\": \"infobox\"})  # Find the infobox table\n",
    "    \n",
    "    informations = soup.find(\"a\", title=\"More information about this page\")\n",
    "    \n",
    "    page_info_url = \"https://en.wikipedia.org\"+informations.get(\"href\")\n",
    "    \n",
    "    page_info_response = requests.get(page_info_url)\n",
    "    \n",
    "    page_info_soup = BeautifulSoup(page_info_response.content, 'html.parser')\n",
    "    \n",
    "    # Find all <tr> tags\n",
    "    rows = page_info_soup.find_all('tr')\n",
    "\n",
    "    # Loop through each row to find the one with the desired structure\n",
    "    for row in rows:\n",
    "        # Find all <td> elements within the row\n",
    "        tds = row.find_all('td')\n",
    "        # Check if there are exactly two <td> elements and if one contains the desired text\n",
    "        if len(tds) == 2 and \"Wikidata item ID\" in tds[0].text:\n",
    "            # Found the desired row, process it as needed\n",
    "            wikidata_id = tds[1].text.strip()\n",
    "        elif len(tds) == 2 and \"Page ID\" in tds[0].text:\n",
    "            page_id = tds[1].text.strip()\n",
    "    \n",
    "    return wikidata_id, page_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikidata_info(wikidata_id, sparqlAgent):\n",
    "    \n",
    "    query = f\"\"\"\n",
    "      SELECT ?film ?filmLabel (MIN(?releaseDate) AS ?earliestReleaseDate) (MAX(?boxOffice) AS ?highestBoxOffice) ?runtime \n",
    "            (GROUP_CONCAT(DISTINCT ?languageLabel; separator=\", \") AS ?languages) \n",
    "            (GROUP_CONCAT(DISTINCT ?countryLabel; separator=\", \") AS ?countries) \n",
    "            (GROUP_CONCAT(DISTINCT ?genreLabel; separator=\", \") AS ?genres)\n",
    "            (GROUP_CONCAT(DISTINCT ?reviewScoreLabel; separator=\", \") AS ?reviewScores)\n",
    "            (GROUP_CONCAT(DISTINCT ?awardLabel; separator=\", \") AS ?awardsReceived)\n",
    "            (GROUP_CONCAT(DISTINCT ?nominatedAwardLabel; separator=\", \") AS ?awardsNominated)\n",
    "            ?capitalCost WHERE {{\n",
    "        BIND(wd:{wikidata_id} AS ?film)  # Using the specific Wikidata movie ID\n",
    "        \n",
    "        ?film wdt:P31 wd:Q11424;  # Instance of film\n",
    "              wdt:P577 ?releaseDate.\n",
    "        \n",
    "        OPTIONAL {{ ?film wdt:P2142 ?boxOffice. }}\n",
    "        OPTIONAL {{ ?film wdt:P2047 ?runtime. }}\n",
    "        OPTIONAL {{ ?film wdt:P364 ?language. ?language rdfs:label ?languageLabel. FILTER(LANG(?languageLabel) = \"en\") }}\n",
    "        OPTIONAL {{ ?film wdt:P495 ?country. ?country rdfs:label ?countryLabel. FILTER(LANG(?countryLabel) = \"en\") }}\n",
    "        OPTIONAL {{ ?film wdt:P136 ?genre. ?genre rdfs:label ?genreLabel. FILTER(LANG(?genreLabel) = \"en\") }}\n",
    "        OPTIONAL {{ ?film wdt:P444 ?reviewScoreLabel. }}\n",
    "        OPTIONAL {{ ?film wdt:P166 ?award. ?award rdfs:label ?awardLabel. FILTER(LANG(?awardLabel) = \"en\") }}\n",
    "        OPTIONAL {{ ?film wdt:P1411 ?nominatedAward. ?nominatedAward rdfs:label ?nominatedAwardLabel. FILTER(LANG(?nominatedAwardLabel) = \"en\") }}\n",
    "        OPTIONAL {{ ?film wdt:P2130 ?capitalCost. }}\n",
    "\n",
    "        SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
    "      }}\n",
    "      GROUP BY ?film ?filmLabel ?runtime ?capitalCost\n",
    "      \"\"\"\n",
    "    \n",
    "    sparqlAgent.setQuery(query)\n",
    "    sparqlAgent.setReturnFormat(JSON)\n",
    "    results = sparqlAgent.query().convert()\n",
    "    \n",
    "    return results['results']['bindings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_film_info(film_title):\n",
    "    wikidata_id, page_id = get_id(film_title)\n",
    "    \n",
    "    if wikidata_id is None:\n",
    "        print(f\"Failed to retrieve Wikidata ID for '{film_title}'.\")\n",
    "        return None\n",
    "    \n",
    "    film_info = get_wikidata_info(wikidata_id, sparql)\n",
    "    \n",
    "    \n",
    "    info = {}\n",
    "    info['page_id'] = page_id\n",
    "    info['wikidata_id'] = wikidata_id\n",
    "    \n",
    "    if len(film_info) == 0:\n",
    "        info['film'] = film_title\n",
    "        info['release_date'] = None\n",
    "        info['box_office'] = None\n",
    "        info['runtime'] = None\n",
    "        info['languages'] = None\n",
    "        info['countries'] = None\n",
    "        info['genres'] = None\n",
    "        info['reviewScores'] = None\n",
    "        info['awardsReceived'] = None\n",
    "        info['awardsNominated'] = None\n",
    "        info['capitalCost'] = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    for film in film_info:\n",
    "        \n",
    "        info['film'] = film['filmLabel']['value']\n",
    "        info['release_date'] = film['earliestReleaseDate']['value']\n",
    "        info['box_office'] = film['highestBoxOffice']['value'] if 'highestBoxOffice' in film else None\n",
    "        info['runtime'] = film['runtime']['value'] if 'runtime' in film else None\n",
    "        info['languages'] = film['languages']['value'] if 'languages' in film else None\n",
    "        info['countries'] = film['countries']['value'] if 'countries' in film else None\n",
    "        \n",
    "        \n",
    "        genres = film['genres']['value'] if 'genres' in film else None\n",
    "        genres = genres.split(\", \") if genres is not None else None\n",
    "        info['genres'] = [genre.replace(\"film\", \"\").strip() for genre in genres if len(genre.split()) <= 2 ]\n",
    "        \n",
    "        reviewScores = film['reviewScores']['value'] if 'reviewScores' in film else None\n",
    "        reviewScores = reviewScores.split(\", \") if reviewScores is not None else None\n",
    "        info['reviewScores'] = reviewScores\n",
    "        \n",
    "        awardsReceived = film['awardsReceived']['value'] if 'awardsReceived' in film else None\n",
    "        awardsReceived = awardsReceived.split(\", \") if awardsReceived is not None else None\n",
    "        info['awardsReceived'] = awardsReceived\n",
    "        \n",
    "        awardsNominated = film['awardsNominated']['value'] if 'awardsNominated' in film else None\n",
    "        awardsNominated = awardsNominated.split(\", \") if awardsNominated is not None else None\n",
    "        info['awardsNominated'] = awardsNominated\n",
    "        \n",
    "        info['capitalCost'] = film['capitalCost']['value'] if 'capitalCost' in film else None\n",
    "\n",
    "        \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = get_film_info(\"The Godfather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikidata_id</th>\n",
       "      <th>film</th>\n",
       "      <th>release_date</th>\n",
       "      <th>box_office</th>\n",
       "      <th>runtime</th>\n",
       "      <th>languages</th>\n",
       "      <th>countries</th>\n",
       "      <th>genres</th>\n",
       "      <th>reviewScores</th>\n",
       "      <th>awardsReceived</th>\n",
       "      <th>awardsNominated</th>\n",
       "      <th>capitalCost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2466773</th>\n",
       "      <td>Q47703</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972-03-15T00:00:00Z</td>\n",
       "      <td>250341816</td>\n",
       "      <td>175</td>\n",
       "      <td>Italian, English</td>\n",
       "      <td>Italy, United States of America</td>\n",
       "      <td>[drama, epic, crime, thriller, gangster, histo...</td>\n",
       "      <td>[100/100, 97%, 9.4/10]</td>\n",
       "      <td>[Golden Globe Award for Best Motion Picture – ...</td>\n",
       "      <td>[Academy Award for Best Director, Academy Awar...</td>\n",
       "      <td>6000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wikidata_id           film          release_date box_office runtime  \\\n",
       "page_id                                                                       \n",
       "2466773      Q47703  The Godfather  1972-03-15T00:00:00Z  250341816     175   \n",
       "\n",
       "                languages                        countries  \\\n",
       "page_id                                                      \n",
       "2466773  Italian, English  Italy, United States of America   \n",
       "\n",
       "                                                    genres  \\\n",
       "page_id                                                      \n",
       "2466773  [drama, epic, crime, thriller, gangster, histo...   \n",
       "\n",
       "                   reviewScores  \\\n",
       "page_id                           \n",
       "2466773  [100/100, 97%, 9.4/10]   \n",
       "\n",
       "                                            awardsReceived  \\\n",
       "page_id                                                      \n",
       "2466773  [Golden Globe Award for Best Motion Picture – ...   \n",
       "\n",
       "                                           awardsNominated capitalCost  \n",
       "page_id                                                                 \n",
       "2466773  [Academy Award for Best Director, Academy Awar...     6000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(infos, orient='index').T\n",
    "df.set_index('page_id', inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013: Retrieved 3325 films.\n",
      "2014: Retrieved 3478 films.\n",
      "2015: Retrieved 3504 films.\n",
      "2016: Retrieved 3447 films.\n",
      "2017: Retrieved 3310 films.\n",
      "2018: Retrieved 3253 films.\n",
      "2019: Retrieved 3317 films.\n",
      "2020: Retrieved 2268 films.\n",
      "2021: Retrieved 2580 films.\n",
      "2022: Retrieved 2887 films.\n",
      "2023: Retrieved 2827 films.\n",
      "2024: Retrieved 2191 films.\n"
     ]
    }
   ],
   "source": [
    "films_since_2013 = {}\n",
    "\n",
    "for year in range(2013, 2025):  # Adjust end year as needed\n",
    "    films = get_films_by_year(year)\n",
    "    films_since_2013[year] = films\n",
    "    print(f\"{year}: Retrieved {len(films)} films.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2013 films:\n",
      "processed film +1 (film).\n",
      "processed film 1 (2013 film).\n",
      "processed film The 1 Up Fever.\n",
      "processed film 1,001 Apples.\n",
      "processed film 2 Autumns, 3 Winters.\n",
      "processed film 2 Guns.\n",
      "processed film 3 Days in Havana.\n",
      "processed film 3 Dots.\n",
      "processed film 3 Geezers!.\n",
      "processed film 3 Peas in a Pod.\n",
      "processed film 3G (film).\n",
      "processed film 3G Love.\n",
      "processed film 3x3D.\n",
      "processed film 5 Sundarikal.\n",
      "processed film 6 (film).\n",
      "processed film 6-5=2.\n",
      "processed film 7 Assassins.\n",
      "processed film 7 Pecados Rurais.\n",
      "processed film 7th Floor.\n",
      "processed film 8-pallo.\n",
      "processed film 9 Full Moons.\n",
      "processed film 9 Meter.\n",
      "processed film 9 Month Stretch.\n",
      "processed film 10 Minutes (2013 film).\n",
      "processed film 10 Rules for Sleeping Around.\n",
      "processed film 10%: What Makes a Hero?.\n",
      "processed film 10,000 Hours (film).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m films:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m film \u001b[38;5;129;01min\u001b[39;00m films:\n\u001b[1;32m----> 6\u001b[0m     film_info \u001b[38;5;241m=\u001b[39m get_film_info(film)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m film_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m         film_dict[film] \u001b[38;5;241m=\u001b[39m film_info\n",
      "Cell \u001b[1;32mIn[29], line 8\u001b[0m, in \u001b[0;36mget_film_info\u001b[1;34m(film_title)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to retrieve Wikidata ID for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilm_title\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m film_info \u001b[38;5;241m=\u001b[39m get_wikidata_info(wikidata_id, sparql)\n\u001b[0;32m     11\u001b[0m info \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     12\u001b[0m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m page_id\n",
      "Cell \u001b[1;32mIn[28], line 34\u001b[0m, in \u001b[0;36mget_wikidata_info\u001b[1;34m(wikidata_id, sparqlAgent)\u001b[0m\n\u001b[0;32m     32\u001b[0m sparqlAgent\u001b[38;5;241m.\u001b[39msetQuery(query)\n\u001b[0;32m     33\u001b[0m sparqlAgent\u001b[38;5;241m.\u001b[39msetReturnFormat(JSON)\n\u001b[1;32m---> 34\u001b[0m results \u001b[38;5;241m=\u001b[39m sparqlAgent\u001b[38;5;241m.\u001b[39mquery()\u001b[38;5;241m.\u001b[39mconvert()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbindings\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\site-packages\\SPARQLWrapper\\Wrapper.py:960\u001b[0m, in \u001b[0;36mSPARQLWrapper.query\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryResult\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    943\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;124;03m    Execute the query.\u001b[39;00m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03m    Exceptions can be raised if either the URI is wrong or the HTTP sends back an error (this is also the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    958\u001b[0m \u001b[38;5;124;03m    :rtype: :class:`QueryResult` instance\u001b[39;00m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m QueryResult(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query())\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\site-packages\\SPARQLWrapper\\Wrapper.py:926\u001b[0m, in \u001b[0;36mSPARQLWrapper._query\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    924\u001b[0m         response \u001b[38;5;241m=\u001b[39m urlopener(request, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout)\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 926\u001b[0m         response \u001b[38;5;241m=\u001b[39m urlopener(request)\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturnFormat\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    537\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPSConnection, req,\n\u001b[0;32m   1392\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context, check_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_hostname)\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\urllib\\request.py:1352\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m   1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m-> 1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1354\u001b[0m     h\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\http\\client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1395\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\http\\client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\http\\client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\wahid\\anaconda3\\envs\\ada\\Lib\\ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "film_dict = {}\n",
    "\n",
    "for year, films in films_since_2013.items():\n",
    "    print(f\"\\n{year} films:\")\n",
    "    for film in films:\n",
    "        film_info = get_film_info(film)\n",
    "        if film_info is not None:\n",
    "            film_dict[film] = film_info\n",
    "            print(f'processed film {film}.')\n",
    "        else:\n",
    "            print(f\"Failed to retrieve information for '{film}'.\")\n",
    "            \n",
    "    df = pd.DataFrame.from_dict(film_dict, orient='index').T\n",
    "    df.to_csv(f'films_{year}.csv')\n",
    "    \n",
    "    film_dict = {}\n",
    "        \n",
    "        \n",
    "    print(f'Processed films for {year}.')\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
