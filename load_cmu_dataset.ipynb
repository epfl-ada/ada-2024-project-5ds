{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579b567a-2b80-4bf1-8cc1-c514da76ca50",
   "metadata": {},
   "source": [
    "# (ADA) Homework 1: Scoring the Language Model Olympics\n",
    "\n",
    "---\n",
    "\n",
    "By the end of this homework, we expect you to be able to:\n",
    "\n",
    "- Load data and handle data using pandas;\n",
    "- Navigate the documentation of Python packages by yourself;\n",
    "- Filter and tidy up noisy real-world datasets;\n",
    "- Aggregate your data in different (and hopefully helpful) ways;\n",
    "- Create meaningful visualizations to analyze the data;\n",
    "- Communicate your findings in a clear and concise manner\n",
    "\n",
    "---\n",
    "\n",
    "**Important Dates.**\n",
    "\n",
    "- Homework release: Fri 04 Oct 2024\n",
    "- Homework due: Sat 18 Oct 2024, 23:59\n",
    "- Grade release: Mon 04 Nov 2024\n",
    "\n",
    "**Some rules**\n",
    "\n",
    "- You are allowed to use any built-in Python library that comes with Anaconda. If you want to use an external library, you may do so, but must justify your choice.\n",
    "- Make sure you use the data folder provided in the repository in read-only mode. (Or alternatively, be sure you don‚Äôt change any of the files.)\n",
    "- Be sure to provide a concise textual description of your thought process, the assumptions you made, the solution you implemented, and explanations for your answers. A notebook that only has code cells will not suffice. To avoid confusion: use short comments for longer code answers.\n",
    "- For questions containing the /Discuss:/ prefix, answer not with code, but with a textual explanation (in markdown).\n",
    "- Back up any hypotheses and claims with data, since this is an important aspect of the course.\n",
    "- Please write all your comments in English, and use meaningful variable names in your code. Your repo should have a single notebook (plus the required data files) in the master/main branch. If there are multiple notebooks present, we will not grade anything.\n",
    "- We will not run your notebook for you! Rather, we will grade it as is, which means that only the results contained in your evaluated code cells will be considered, and we will not see the results in unevaluated code cells. Thus, be sure to hand in a fully-run and evaluated notebook. In order to check whether everything looks as intended, you can check the rendered notebook on the GitHub website once you have pushed your solution there.\n",
    "- In continuation to the previous point, interactive plots, such as those generated using the ‚Äòplotly‚Äô package, should be strictly avoided! Make sure to print results and/or dataframes that confirm you have properly addressed the task.\n",
    "\n",
    "**A Note on using Language Models (LMs)**\n",
    "\n",
    "If you try hard enough, you will likely get away with cheating. Fortunately, our job is not to police, but rather to educate! So, please consider the following:\n",
    "- Presumably, you are taking this course to learn something! LMs are not always right ([they often fail in silly ways](https://community.openai.com/t/why-9-11-is-larger-than-9-9-incredible/869824/4)). This course should prepare you to detect when they are wrong!\n",
    "- Some of the TAs on this course literally published many works on detecting machine-generated text.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b666deed-9c5a-4d3f-9e83-98131dc9344a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f85896e-c0ae-4ae3-af41-46149faa2278",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "Context\n",
    "AI is booming! Newspapers, influencers, and your relatives all agree that AI is important. But while almost everyone agrees that AI is the future, much is unclear about what that future looks like‚Ä¶\n",
    "\n",
    "Freshly graduated from the EPFL, you are hired by the Swiss government to advise on a large-scale ‚ÄúAI integration‚Äù initiative code-named **\"NEUTRALITY\"** (Navigating Efficient Upgrades Through Robust Artificial Learning Integration Techniques Yearly). Convinced by the stunning progress in language modeling, the government would like to battle the growing shortages in the education sector by using LMs. Your job description: investigate which LMs might be best suited!\n",
    "\n",
    "You are given the results of three LMs on the [‚ÄúMassive Multitask Language Understanding (MMLU)‚Äù](https://arxiv.org/abs/2009.03300) dataset to compare. This famous dataset consists of 57 subjects with multiple-choice questions, covering diverse subjects like mathematics, computer science, history, and law. Most providers of state-of-the-art LMs use this dataset to showcase the versatility of their latest models. Unfortunately, Horta-Ribeiro, the intern responsible for collecting the results, didn‚Äôt take EPFL‚Äôs famous ADA course. As a result, the collected datasets are slightly corrupted.\n",
    "\n",
    "### A very brief primer on Language Models\n",
    "Language models (LMs) are sophisticated statistical models designed to understand and generate human-like text. At their core, LMs are trained to predict the most likely continuation of a given input text. For example, given the input \"The cat sat on the,\" an LM might predict \"mat\" as a likely continuation.\n",
    "LMs are trained on vast text samples from various sources, including books, websites, and social media. This extensive training allows them to capture patterns and relationships in language, enabling them to generate coherent and contextually appropriate text across a wide range of topics and styles.\n",
    "\n",
    "While LMs can produce text that appears to be written by intelligent humans, it's important to note that their capabilities can diverge from human intelligence in unexpected ways. They may sometimes generate factually incorrect information or struggle with complex reasoning tasks.\n",
    "\n",
    "Two key concepts in understanding LMs are:\n",
    "1. **Tokens**: LMs process text using \"tokens\" rather than individual characters. Tokens can be words, parts of words, or punctuation marks. For example, the sentence \"I love AI!\" might be tokenized as [\"I\", \"love\", \"AI\", \"!\"]. Tokenization is the first step in both training and using an LM.\n",
    "2. **Context**: The input text provided to an LM is called the \"context.\" This context informs the model's predictions or generations. A longer or more specific context often leads to more accurate and relevant outputs.\n",
    "\n",
    "[See: Wikipedia entry on language models](https://en.wikipedia.org/wiki/Large_language_model)\n",
    "\n",
    "###  Files for this assignment\n",
    "This assignment is divided into three tasks, each of which should bring you a step closer to providing a recommendation toward project NEUTRALITY‚Äôs objectives:\n",
    "\n",
    "- **Task 1**: Inspecting the results and getting your first model ranking\n",
    "- **Task 2**: Inspecting the underlying data used to generate the results for possible biases\n",
    "- **Task 3**: Learning about tokens and providing a final recommendation\n",
    "\n",
    "\n",
    "```\n",
    "üìÅ PROJECT_NEUTRALITY\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ üìÑ analysis.ipynb (the file you're currently reading!)\n",
    "‚îú‚îÄ‚îÄ üìÑ requirements.txt (install into your environment)\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ üìÅ task_1\n",
    "‚îú‚îÄ‚îÄ üìÅ task_2\n",
    "‚îî‚îÄ‚îÄ üìÅ task_2.5\n",
    "```   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ce4c12-9681-401e-9489-aa0765b19d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please make sure you install the packages listed in the requirements.txt file in your environment!\n",
    "# using pip\n",
    "# pip install -r requirements.txt\n",
    "#\n",
    "# using Conda:\n",
    "# conda create --name <env_name> --file requirements.txt\n",
    "#\n",
    "# some basic imports\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62594ad-4f5f-4a46-80bc-deacf66b62e9",
   "metadata": {},
   "source": [
    "## Task 1 (18 points): What's in an average anyway?\n",
    "\n",
    "The files needed to complete task 1 can be found in the folder \"`data/task_1/`:\n",
    "```\n",
    "task_1/\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ mmlu_data/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ test.csv\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ lm_scores/\n",
    "    ‚îú‚îÄ‚îÄ lm_X.csv\n",
    "    ‚îú‚îÄ‚îÄ lm_Y.csv\n",
    "    ‚îî‚îÄ‚îÄ lm_Z.csv\n",
    "```\n",
    "\n",
    "We will start by loading, (manually) inspecting, and cleaning the data. Although it doesn't seem \"glamorous\" (nor is it particularly fun...) - manually inspecting data is extremely important! In fact, it's one of the few things most AI and Data Science researchers agree on :). Next, we will take a first pass on ordering our Olympic podium between three LMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8605646-79fa-4cb3-8137-b6951bd1e064",
   "metadata": {},
   "source": [
    "### 1.1 (1 pt)\n",
    " \n",
    "Load the subfiles contained in the `mmlu_data` and `lm_scores` folders into separate dataframes:\n",
    "- `df_test`\n",
    "- `df_x`\n",
    "- `df_y`\n",
    "- `df_z`\n",
    "\n",
    "for each, print their sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6ce5e96-7de6-463d-a00b-6a4b2cfc8cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'ada-2024-homework-1-5ds/task_1/'\n",
    "df_test = pd.read_csv(data_folder + 'mmlu_data/test.csv')\n",
    "\n",
    "df_x = pd.read_csv(data_folder + 'lm_scores/lm_X.csv')\n",
    "df_y = pd.read_csv(data_folder + 'lm_scores/lm_Y.csv')\n",
    "df_z = pd.read_csv(data_folder + 'lm_scores/lm_Z.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4041493f-af52-4ac4-89dc-e5a18e65fc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112336"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "784fd5a5-7e40-41fb-ad17-d70342551583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27764"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "627d880c-1016-4036-ba51-93d5abded775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27956"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a8e459b-88b1-442f-858c-01a68fa7322b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27846"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_z.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbda57d-7df2-4e33-b31c-52bc0af6753e",
   "metadata": {},
   "source": [
    "### 1.2 (4 pt)\n",
    "Unfortunately, LMs don't always output the format we want. In the column `result`, the value should be one of A, B, C, or D. \n",
    "\n",
    "A. For each of the LM score dataframes, use a `value_counts()` operation and print the results. \n",
    "\n",
    "B. /Discuss:/ Inspect the results and describe the types of answer formats you see. Besides the \"expected\" case, you should be able to find at least four unexpected formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a413784-92f4-4993-b523-4524b89d248a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result\n",
       "D                                                                                                2894\n",
       "Answer: D                                                                                        1718\n",
       "C                                                                                                1701\n",
       "B                                                                                                1240\n",
       "D                                                                                                1145\n",
       "                                                                                                 ... \n",
       "Where the energy of interaction between the atoms is at its minimum value, so the answer is A       1\n",
       "leaves more viable offspring than others of its species., so the answer is D                        1\n",
       "A and C only, so the answer is D                                                                    1\n",
       "ADP + P ‚Üí ATP, so the answer is D                                                                   1\n",
       "Monoclonal antibodies, so the answer is C                                                           1\n",
       "Name: count, Length: 141, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y['result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ee16eba-c96a-455a-95b8-c7c70a8fdf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result\n",
       "D                                                                                   2257\n",
       "C                                                                                   2191\n",
       "B                                                                                   2127\n",
       "A                                                                                   2060\n",
       "Answer: D                                                                            777\n",
       "                                                                                    ... \n",
       "omission of a universal suffrage clause, so the answer is D                            1\n",
       "declare war, so the answer is D                                                        1\n",
       "state and local governments, by means of federal funding, so the answer is B           1\n",
       "less clearly identified with consistent political ideologies, so the answer is B       1\n",
       "Rahit, so the answer is B                                                              1\n",
       "Name: count, Length: 560, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_z['result'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f9f45-7581-4fa7-8535-b37bf1e6fd33",
   "metadata": {},
   "source": [
    "B)\\\n",
    "After we displayed the value count for the 3 LMs result we can see that it's not always the expected format A,B,C,D, we observe different formats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2864b1e5-eb04-4b9f-9c39-0e656f7a59b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'C', 'D ', 'B ', 'Answer: B', 'A', 'Answer: D', 'Answer: C',\n",
       "       'Answer: A', 'Not Sure', 'A ', 'C ', nan, 'D', 'None of the above',\n",
       "       '3, so the answer is B',\n",
       "       'is prevented from everting by papillary muscles., so the answer is B',\n",
       "       'lingual branch of the mandibular trigeminal nerve., so the answer is A',\n",
       "       'These craters contain the only permanently shadowed regions on Mercury, so the answer is D',\n",
       "       'Unsafe practices, Wants, Fear, Trivial, so the answer is A',\n",
       "       'phosphofructokinase., so the answer is D',\n",
       "       'They provide access to phosphorus, an essential element that is limited in many kinds of soils., so the answer is C',\n",
       "       'Lead to death due to an inability of the cell to pass electrons to oxygen, thus stopping aerobic respiration and asphyxiating the cells., so the answer is A',\n",
       "       'creatine phosphorylation., so the answer is B',\n",
       "       'Mass of the moon, so the answer is A', '5, so the answer is A',\n",
       "       'True, True, so the answer is A',\n",
       "       'By overwriting the return address to point to the location of that code, so the answer is A',\n",
       "       'passes into the air above, so the answer is B',\n",
       "       'torques, so the answer is B',\n",
       "       'one-quarter the value for a tube open at both ends, so the answer is A',\n",
       "       'ejected neutrons, so the answer is D',\n",
       "       'internal reflection, so the answer is A',\n",
       "       'No, so the answer is B', 'crystal filter., so the answer is B',\n",
       "       'Inductance., so the answer is B',\n",
       "       'Both 2 and 3., so the answer is D',\n",
       "       'in parallel., so the answer is B', 'C =8œÄ, so the answer is B',\n",
       "       'Invalid. Counterexample when L is true and K is false, so the answer is D',\n",
       "       '(‚àÄx)(Rx ‚äÉ Ax), so the answer is C', '80%, so the answer is C',\n",
       "       'The appendix has a substantial amount of defensive lymphatic tissue., so the answer is C',\n",
       "       'proximal convoluted tubule, so the answer is B',\n",
       "       'Chemiosmosis, so the answer is B',\n",
       "       'temporary dipoles created by the position of electrons around the nuclei in a molecule, so the answer is A',\n",
       "       'Second order, so the answer is C',\n",
       "       '1 and 2 because they both reduce copper ions, so the answer is C',\n",
       "       'David Hume, so the answer is D',\n",
       "       'A congressperson who retires to take a position teaching political science at a university, so the answer is A',\n",
       "       'creating insurmountable obstacles to the founding of factions, so the answer is A',\n",
       "       'judicial activism, so the answer is A',\n",
       "       'voters select the winner by caucus instead of by individual ballots, so the answer is A',\n",
       "       'Fifty-one percent, so the answer is B', '13, so the answer is C',\n",
       "       '(‚Äì3, 2), so the answer is C', 'sweet, so the answer is B',\n",
       "       'remembering how to tie a tie, so the answer is B',\n",
       "       'anger, so the answer is A',\n",
       "       'the conditioned stimulus without the unconditioned stimulus, so the answer is B',\n",
       "       '70 minutes to 264 minutes, so the answer is C',\n",
       "       '6.68%, so the answer is D',\n",
       "       'Conservation, trust-busting, consumer protection, so the answer is A',\n",
       "       'it was the first time the presidency shifted from one political party to another., so the answer is B',\n",
       "       'Unregulated currency and federal debts after the War of 1812, so the answer is B',\n",
       "       'H. Ross Perot, Reform Party, 1996, so the answer is D',\n",
       "       'Overhunting and depletion of furbearing animals, so the answer is D',\n",
       "       'The world engages in subtler forms of discrimination., so the answer is B',\n",
       "       'All adult men born within the geographic boundaries of the state, so the answer is A',\n",
       "       'Large-scale military losses and resentment of the working classes, so the answer is C',\n",
       "       'One can make funeral and estate plans with the loved one, so the answer is B',\n",
       "       'Changes a lot past age 50, so the answer is A',\n",
       "       'experienced guilt, so the answer is C',\n",
       "       'No, according to the literal interpretation of the relevant provision of the State, the provisional measures are not binding, so the answer is A',\n",
       "       'False, False, so the answer is B',\n",
       "       'Linear hard-margin SVM., so the answer is A',\n",
       "       'Whether we assume full class covariance matrices or diagonal class covariance matrices, so the answer is B',\n",
       "       'True, False, so the answer is C',\n",
       "       'Adam Smith, so the answer is C',\n",
       "       'quantity demanded barely changes with a change in price, so the answer is B',\n",
       "       'Autosomal recessive, so the answer is B',\n",
       "       '6*10^14 J, so the answer is C', 'white, so the answer is C',\n",
       "       'six years, so the answer is C', 'Paris, so the answer is A',\n",
       "       'up to 250, so the answer is A', 'Chordates, so the answer is B',\n",
       "       'Losing the curl, so the answer is C',\n",
       "       'Bill Viola, so the answer is A',\n",
       "       'Conceptual artists, so the answer is D',\n",
       "       'the type of drug used, so the answer is A',\n",
       "       'Not wrong, Wrong, so the answer is C',\n",
       "       'Wrong, Wrong, so the answer is A',\n",
       "       'Not wrong, Not wrong, so the answer is D',\n",
       "       'Vitamin D, so the answer is B',\n",
       "       'Folate, vitamins B6 and B12, so the answer is D',\n",
       "       'purely physical and natural, so the answer is B',\n",
       "       'logical nominalism, so the answer is A',\n",
       "       'enlightened egoism., so the answer is A',\n",
       "       'food surpluses, specialists, urban settlements, and a system of record keeping, so the answer is A',\n",
       "       'philosophy and religion., so the answer is B',\n",
       "       'Acheulean, so the answer is B',\n",
       "       'Neandertals used caves in Europe where their remains were preserved., so the answer is B',\n",
       "       'tribute in the form of gold, jade, feathers, cloth, and jewels., so the answer is A',\n",
       "       'No, because Long did not have authority to enter into the contract., so the answer is D',\n",
       "       '$100,000, so the answer is A', '10%, so the answer is A',\n",
       "       '$480,000, so the answer is B',\n",
       "       \"not recover, because the dairy's negligence only caused mental disturbance., so the answer is C\",\n",
       "       'constitutional, because the election code is nonviolative of the equal protection clause., so the answer is D',\n",
       "       'Because window tinting is permitted on vehicles in neighboring states, this law denies the company the equal protection of laws., so the answer is A',\n",
       "       'No, she is not a member of a suspect class as there cannot be a \"class-of-one\" in the employment law context., so the answer is A',\n",
       "       'Yes, because the aluminum sheets were nonconforming goods., so the answer is A',\n",
       "       'the contract price of$10,000., so the answer is C',\n",
       "       'recover, if a reasonable consumer would not expect the presence of such a pebble in the chowder., so the answer is A',\n",
       "       \"The zoning ordinance provision would be upheld as constitutional under the state's police power., so the answer is D\",\n",
       "       'Although the contract violates the law and is void, the court will require the homeowner to pay the contractor the reasonable value of the work accepted., so the answer is A',\n",
       "       'it is necessary to further a compelling state interest., so the answer is B',\n",
       "       'No, because the retailer is a citizen of State B., so the answer is B',\n",
       "       'first-degree murder., so the answer is A',\n",
       "       'The defendant is compelled to stand trial in street clothing., so the answer is B',\n",
       "       'They committed a larceny by placing the three dresses in the shopping bag., so the answer is A',\n",
       "       'the right to remove oil is an incident of a defeasible fee simple., so the answer is A',\n",
       "       'sustain the objection, because the radar results are not conclusive evidence of speeding., so the answer is A',\n",
       "       'Cytokine secretion by natural killer cells, so the answer is A',\n",
       "       'Apocrine gland, so the answer is A',\n",
       "       'needs analysis., so the answer is A',\n",
       "       'goals serve 2 purposes: they are a basis for motivation and they direct behaviors, so the answer is A',\n",
       "       'effect of an IV at diff levels of the other IVs, so the answer is A',\n",
       "       'Cognitive behavioral therapy, so the answer is A',\n",
       "       'high ability and low motivation., so the answer is C',\n",
       "       'brain damage, intellectual disability, or emotional disturbance, so the answer is D',\n",
       "       'the student should be listed as the first author., so the answer is A',\n",
       "       'we tend to remember unfinished tasks better than finished ones., so the answer is A',\n",
       "       'only if the employee was referred to the program by the supervisor., so the answer is B',\n",
       "       'a simultaneous event produced the fluctuation, so the answer is A',\n",
       "       'Random assignment, random selection, so the answer is B',\n",
       "       'to interpret trends for management, so the answer is B',\n",
       "       'Strategic studies are the central concern of international relations, within strategic studies, the subset of security studies focuses on military security., so the answer is A',\n",
       "       'Complete eradication of threats., so the answer is A',\n",
       "       'Category B agents include food and water security threats, with moderate morbidity rates., so the answer is C',\n",
       "       'It is when considering the military and the security institutions that some of the greatest contradictions with the concept of environmental security are raised. War impacts negatively on the sustainable growth of the nation but armed forces may be required to manage the effects., so the answer is B',\n",
       "       'household account book, so the answer is C',\n",
       "       'China, so the answer is D',\n",
       "       'It criticized international organizations, rather than trying to strengthen them, so the answer is A',\n",
       "       'Brahminic orthodoxy, so the answer is A'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x['result'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbbd4eb-7f32-4d6b-9a2b-1ae8cec95da3",
   "metadata": {},
   "source": [
    "1 - Some values in the result column contain a text followed or precced by the actual answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4d69c0-3281-46e7-bcde-fa1117105d1c",
   "metadata": {},
   "source": [
    "2 - Since the answer is a string, there can be a space or no space after the answer letter, and this is counted differently, see example below, where the first one count the number of A with a space after and the second one without :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0554638b-aece-4fa4-9fb4-634cf01cbc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1657"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(df_x['result'] == 'A ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb05d113-9b40-41cc-8539-2b5ebedd943f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2733"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(df_x['result'] == 'A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d1803-ba5c-4767-9bab-652e0e4d0a75",
   "metadata": {},
   "source": [
    "As we can see when we do the np.unqique on df_x, some results doesnt have any answers and instead have not sure or none of the above or even a Nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c5551d-1968-427b-bdd6-51d996898e7c",
   "metadata": {},
   "source": [
    "### 1.3 (5 pt)\n",
    "Oh oh... That doesn't look great. Simply dropping all invalid answers seems overly wasteful, yet fixing all of these looks like a mess! Instead, let's focus for now on fixing just those answers of length < 10 characters that require only a single `str.replace()` operation. \n",
    "\n",
    "For example, if the answer looks like `--A--`, we could fix this by using the following simple function:\n",
    "\n",
    "```\n",
    "def clean_answer(s, pattern='-'):\n",
    "    return str(s).replace(pattern, '')\n",
    "\n",
    "dirty_answer = '--A--'\n",
    "clean_answer = clean_answer(dirty_answer)\n",
    "```\n",
    "\n",
    "A. Filter the three score dataframes to include only answers with less than 10 characters. Make a deep copy of the dataframes as you filter them.\n",
    "\n",
    "B. Modify the `clean_answer()` example function to clean the answers in the filtered data frames using the `apply()` functionality. Finally, make sure **all remaining answers are one of `A, B, C, or D`.**\n",
    "\n",
    "C. /Discuss:/ Compare the sizes of the original and filtered data frames. What do you see? Why might this be a problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aef1f933-20bf-426a-ac9d-a35e273b9bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A\n",
    "df_x_filter = df_x.query('result.str.len() < 10 & result != \"Not Sure\"').copy(deep = True)\n",
    "df_y_filter = df_y.query('result.str.len() < 10 & result != \"Not Sure\"').copy(deep = True)\n",
    "df_z_filter = df_z.query('result.str.len() < 10 & result != \"Not Sure\"').copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0c14241-89c8-4263-8e3c-995d01690b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'A ', 'Answer: A', 'Answer: B', 'Answer: C', 'Answer: D', 'B',\n",
       "       'B ', 'C', 'C ', 'D', 'D '], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_x_filter['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd54f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B\n",
    "def clean_answer(s, pattern='Answer: '):\n",
    "    return str(s).replace(pattern, '').strip()\n",
    "\n",
    "df_x_filter['result'] = df_x_filter['result'].apply(clean_answer)\n",
    "df_y_filter['result'] = df_y_filter['result'].apply(clean_answer)\n",
    "df_z_filter['result'] = df_z_filter['result'].apply(clean_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0ca9d49-2bbf-479a-9a4d-008873b587d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_filter['result'] = df_x_filter['result'].apply(lambda s : clean_answer(s)).copy(deep = True).dropna()\n",
    "df_y_filter['result'] = df_y_filter['result'].apply(lambda s : clean_answer(s)).copy(deep = True).dropna()\n",
    "df_z_filter['result'] = df_z_filter['result'].apply(lambda s : clean_answer(s)).copy(deep = True).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9212925a-828b-4742-aa6a-7df5652ea6fe",
   "metadata": {},
   "source": [
    "Let's make sure the remaining answers are indeed A, B, C or D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bc24abf-dc69-47e7-9929-d1e9b25ea502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result\n",
       "A    5788\n",
       "B    2965\n",
       "C    2350\n",
       "D    2333\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_filter['result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb1de63f-2690-4d16-bf31-9ed50f2ddb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13436, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24778a28-b189-44a3-9121-cda511434e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result\n",
       "D    5757\n",
       "C    3242\n",
       "B    2519\n",
       "A    2033\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_filter['result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc37df06-01ac-4733-8f6a-4777fa49fb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26872"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_filter.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35e3c738-0f51-4129-8c1e-badf73a1839e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27102"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_filter.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e7d2924-fddc-4255-b7e9-29257fd60342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25506"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_z_filter.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "510b7380-a198-4452-8b51-4cb493d49bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result\n",
       "D    3348\n",
       "C    3255\n",
       "B    3124\n",
       "A    3026\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_z_filter['result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a218ad3-4f1d-4b31-9603-e870bcf319ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df_x_filter['result']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3352b954-2482-4e36-9e67-91a8cb765ac0",
   "metadata": {},
   "source": [
    "Seems like the clean answer worked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2415cd9b",
   "metadata": {},
   "source": [
    "C. /Discuss:/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cd6b809-d149-47a7-a1a7-44c5556ffd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_percentage_x = 100 - (df_x_filter.size / df_x.size) * 100\n",
    "reduction_percentage_y = 100 - (df_y_filter.size / df_y.size) * 100\n",
    "reduction_percentage_z = 100 - (df_z_filter.size / df_z.size) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ec84135-7c43-4dbe-90fe-37b4843f791a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After we filtered the LM x answers, we had a size diminution of : 3.2127935455986147%\n",
      "After we filtered the LM y answers, we had a size diminution of : 3.05480040062956%\n",
      "After we filtered the LM z answers, we had a size diminution of : 8.403361344537814%\n"
     ]
    }
   ],
   "source": [
    "print(f'After we filtered the LM x answers, we had a size diminution of : {reduction_percentage_x}%')\n",
    "print(f'After we filtered the LM y answers, we had a size diminution of : {reduction_percentage_y}%')\n",
    "print(f'After we filtered the LM z answers, we had a size diminution of : {reduction_percentage_z}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b75b7fd-871f-4765-a5ca-fdec5e248626",
   "metadata": {},
   "source": [
    "LMs x and y had almost the same percentage of answers with less than 10 characters, but this cant be say for LM z that has more than twice the percentage amount of answers of length more than 10. This can lead to incorrect conclusions because of an unbalance dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1cf129-09dd-47b1-9737-2c4d57eb8853",
   "metadata": {},
   "source": [
    "### 1.4 (3 pt)\n",
    "\n",
    "Now that our answer columns are nicely formatted, let's take a look at model performance:\n",
    "\n",
    "A. Both the `MMLU` dataframes and the language model score data frames have the columns `question_id`. For each of the language model score data frames, use an inner join operation with the `df_test` dataframe on the `question_id` column.\n",
    "\n",
    "B. Add a new column to each of the resulting dataframes called `correct`, that checks if the model's answer in `result` is the same as the expected answer in the column `answer`. Then, print the average score of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de5060c1-76b3-4bb5-83a2-229781b38a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e66b36f3-f5a4-4237-9b48-39b21716d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_merged = df_x_filter.merge(right = df_test, how = 'inner', on = 'question_id')\n",
    "df_y_merged = df_y_filter.merge(right = df_test, how = 'inner', on = 'question_id')\n",
    "df_z_merged = df_z_filter.merge(right = df_test, how = 'inner', on = 'question_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b183b8e3-ad6b-418b-834b-3b747e955952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50b024d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_merged['correct'] = df_x_merged['result'] == df_x_merged['answer']\n",
    "df_y_merged['correct'] = df_y_merged['result'] == df_y_merged['answer']\n",
    "df_z_merged['correct'] = df_z_merged['result'] == df_z_merged['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06005710-dd33-4a89-81d4-f27379ab3460",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_x = (df_x_merged['correct'].sum()/(len(df_x_merged['correct'])))*100\n",
    "score_y = (df_y_merged['correct'].sum()/(len(df_y_merged['correct'])))*100\n",
    "score_z = (df_z_merged['correct'].sum()/(len(df_z_merged['correct'])))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54a89363-2bb2-49b8-b32c-d67a79619c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In average the model x answers 76.74903245013397% of the time correclty \n",
      "In average the model x answers 74.58490148328536% of the time correclty \n",
      "In average the model x answers 66.3294911001333% of the time correclty \n"
     ]
    }
   ],
   "source": [
    "print(f'In average the model x answers {score_x}% of the time correclty ')\n",
    "print(f'In average the model x answers {score_y}% of the time correclty ')\n",
    "print(f'In average the model x answers {score_z}% of the time correclty ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69decfd8-8083-4c2f-8263-a153d55efede",
   "metadata": {},
   "source": [
    "### 1.5 (5 pt)\n",
    "\n",
    "Hmmm, something doesn't seem quite right. Let's investigate how \"balanced\" this dataset is:\n",
    "\n",
    "A. For each of the 57 subjects in the MMLU, compare the number of questions answered by each model. Print the subjects for which there is a more than 10% difference.\n",
    "\n",
    "B. Propose and implement a reasonable way to rebalance the results. (e.g., while throwing away 100% of the results perfectly rebalances the results, it is not reasonable).\n",
    "\n",
    "C. Finally, print the updated accuracy on the rebalanced data.\n",
    "\n",
    "**hint:**:\n",
    "- (A) For a given subject, let model X and model Y have answered 181 and 200 questions respectively. You can consider this a 10% difference from the perspective of X since: (200 - 181) / 181 > 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a052d09e-7b31-41ec-bb94-22c21bc89655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>result</th>\n",
       "      <th>question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "      <th>subject</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>Find the degree for the given field extension ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the i...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>C</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>Find all zeros in the indicated finite field o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,1</td>\n",
       "      <td>0,4</td>\n",
       "      <td>D</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>Statement 1 | A factor group of a non-Abelian ...</td>\n",
       "      <td>True, True</td>\n",
       "      <td>False, False</td>\n",
       "      <td>True, False</td>\n",
       "      <td>False, True</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>Find the product of the given polynomials in t...</td>\n",
       "      <td>2x^2 + 5</td>\n",
       "      <td>6x^2 + 4x + 6</td>\n",
       "      <td>0</td>\n",
       "      <td>x^2 + 1</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13431</th>\n",
       "      <td>14037</td>\n",
       "      <td>A</td>\n",
       "      <td>What has been a central focus of religious tra...</td>\n",
       "      <td>Peace and harmony</td>\n",
       "      <td>Power and influence</td>\n",
       "      <td>Truth and love</td>\n",
       "      <td>Wisdom and ethics</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13432</th>\n",
       "      <td>14038</td>\n",
       "      <td>A</td>\n",
       "      <td>To whom did ordinary folk appeal during a dro...</td>\n",
       "      <td>The Buddha</td>\n",
       "      <td>Laozi</td>\n",
       "      <td>The Queen Mother of the West</td>\n",
       "      <td>Confucius</td>\n",
       "      <td>C</td>\n",
       "      <td>world religions</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13433</th>\n",
       "      <td>14039</td>\n",
       "      <td>B</td>\n",
       "      <td>The theological term homoousios means which o...</td>\n",
       "      <td>of a similar substance</td>\n",
       "      <td>of the same substance</td>\n",
       "      <td>of like substance</td>\n",
       "      <td>of human substance</td>\n",
       "      <td>B</td>\n",
       "      <td>world religions</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13434</th>\n",
       "      <td>14040</td>\n",
       "      <td>B</td>\n",
       "      <td>According to the Japanese origin myth, who giv...</td>\n",
       "      <td>Es</td>\n",
       "      <td>Izanagi</td>\n",
       "      <td>Izanami</td>\n",
       "      <td>Kami</td>\n",
       "      <td>B</td>\n",
       "      <td>world religions</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13435</th>\n",
       "      <td>14041</td>\n",
       "      <td>A</td>\n",
       "      <td>The numen of Augustus referred to which of th...</td>\n",
       "      <td>Divine power</td>\n",
       "      <td>Sexual virility</td>\n",
       "      <td>Military acumen</td>\n",
       "      <td>Philosophical intellect</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13436 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_id result                                           question  \\\n",
       "0                0      B  Find the degree for the given field extension ...   \n",
       "1                1      C  Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the i...   \n",
       "2                2      D  Find all zeros in the indicated finite field o...   \n",
       "3                3      B  Statement 1 | A factor group of a non-Abelian ...   \n",
       "4                4      B  Find the product of the given polynomials in t...   \n",
       "...            ...    ...                                                ...   \n",
       "13431        14037      A  What has been a central focus of religious tra...   \n",
       "13432        14038      A   To whom did ordinary folk appeal during a dro...   \n",
       "13433        14039      B   The theological term homoousios means which o...   \n",
       "13434        14040      B  According to the Japanese origin myth, who giv...   \n",
       "13435        14041      A   The numen of Augustus referred to which of th...   \n",
       "\n",
       "                            A                      B  \\\n",
       "0                           0                      4   \n",
       "1                           8                      2   \n",
       "2                           0                      1   \n",
       "3                  True, True           False, False   \n",
       "4                    2x^2 + 5          6x^2 + 4x + 6   \n",
       "...                       ...                    ...   \n",
       "13431       Peace and harmony    Power and influence   \n",
       "13432              The Buddha                  Laozi   \n",
       "13433  of a similar substance  of the same substance   \n",
       "13434                      Es                Izanagi   \n",
       "13435            Divine power        Sexual virility   \n",
       "\n",
       "                                  C                        D answer  \\\n",
       "0                                 2                        6      B   \n",
       "1                                24                      120      C   \n",
       "2                               0,1                      0,4      D   \n",
       "3                       True, False              False, True      B   \n",
       "4                                 0                  x^2 + 1      B   \n",
       "...                             ...                      ...    ...   \n",
       "13431                Truth and love        Wisdom and ethics      A   \n",
       "13432  The Queen Mother of the West                Confucius      C   \n",
       "13433             of like substance       of human substance      B   \n",
       "13434                       Izanami                     Kami      B   \n",
       "13435               Military acumen  Philosophical intellect      A   \n",
       "\n",
       "                subject  correct  \n",
       "0      abstract algebra     True  \n",
       "1      abstract algebra     True  \n",
       "2      abstract algebra     True  \n",
       "3      abstract algebra     True  \n",
       "4      abstract algebra     True  \n",
       "...                 ...      ...  \n",
       "13431   world religions     True  \n",
       "13432   world religions    False  \n",
       "13433   world religions     True  \n",
       "13434   world religions     True  \n",
       "13435   world religions     True  \n",
       "\n",
       "[13436 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19463002-732b-405b-8b44-77f702bdb665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A\n",
    "df_x_number_questions_per_subject = df_x_merged.groupby('subject').aggregate({\"question_id\" : 'count'}).rename(columns={'question_id': 'count'})\n",
    "df_y_number_questions_per_subject = df_y_merged.groupby('subject').aggregate({\"question_id\" : 'count'}).rename(columns={'question_id': 'count'})\n",
    "df_z_number_questions_per_subject = df_z_merged.groupby('subject').aggregate({\"question_id\" : 'count'}).rename(columns={'question_id': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2c90387-f51b-4a89-8496-aa5f32c3813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_x_y = (np.abs(df_x_number_questions_per_subject - df_y_number_questions_per_subject)/df_y_number_questions_per_subject).rename(columns={'count': 'percentage_difference'})\n",
    "difference_x_z = (np.abs(df_x_number_questions_per_subject - df_z_number_questions_per_subject)/df_z_number_questions_per_subject).rename(columns={'count': 'percentage_difference'})\n",
    "difference_y_z = (np.abs(df_y_number_questions_per_subject - df_z_number_questions_per_subject)/df_z_number_questions_per_subject).rename(columns={'count': 'percentage_difference'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6cd57cee-25b4-4029-9a2d-9df4c4ef1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_difference_x_y = list(difference_x_y[difference_x_y['percentage_difference'] > 0.10].index)\n",
    "subject_difference_x_z = list(difference_x_z[difference_x_z['percentage_difference'] > 0.10].index)\n",
    "subject_difference_y_z = list(difference_y_z[difference_y_z['percentage_difference'] > 0.10].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f913582-157a-4bee-ba51-4e58bf70eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "different_subject = list(set(subject_difference_x_y + subject_difference_x_z + subject_difference_y_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df5da664-29ad-413e-8695-fa30447500d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subjects where there is a number of questions difference more than 10 % are : ['moral scenarios', 'college computer science', 'formal logic', 'high school geography', 'medical genetics', 'logical fallacies', 'moral disputes', 'college chemistry', 'computer security']\n"
     ]
    }
   ],
   "source": [
    "print(f'The subjects where there is a number of questions difference more than 10 % are : {different_subject}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fb8c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea312525-d9ac-4b3f-97db-17c6446d2267",
   "metadata": {},
   "source": [
    "To rebalance the results we could see how many times the model is right for each subject and create randomly with the same correct subject percentage some answers to match the number of the other LMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a31335b-3532-4339-bf4d-86ba29c4d211",
   "metadata": {},
   "source": [
    "Let's compute for each subject the average correct answer prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d18dfda-76f6-434b-a45f-b962501f4d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_correct_percentage_subject = (df_x_merged.groupby('subject').aggregate({'correct' : 'sum'})/df_x_merged.groupby('subject').aggregate({'correct' : 'count'})).reset_index()\n",
    "df_y_correct_percentage_subject = (df_y_merged.groupby('subject').aggregate({'correct' : 'sum'})/df_y_merged.groupby('subject').aggregate({'correct' : 'count'})).reset_index()\n",
    "df_z_correct_percentage_subject = (df_z_merged.groupby('subject').aggregate({'correct' : 'sum'})/df_z_merged.groupby('subject').aggregate({'correct' : 'count'})).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6eefdd3-7ce9-4420-9d14-03a7ad748aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anatomy</td>\n",
       "      <td>0.775194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business ethics</td>\n",
       "      <td>0.734694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clinical knowledge</td>\n",
       "      <td>0.791506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>college biology</td>\n",
       "      <td>0.820144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>college chemistry</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>college computer science</td>\n",
       "      <td>0.752577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>college mathematics</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>college medicine</td>\n",
       "      <td>0.732143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>college physics</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>computer security</td>\n",
       "      <td>0.810526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>conceptual physics</td>\n",
       "      <td>0.774336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>econometrics</td>\n",
       "      <td>0.803571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>electrical engineering</td>\n",
       "      <td>0.780142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>elementary mathematics</td>\n",
       "      <td>0.765668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>formal logic</td>\n",
       "      <td>0.788991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>global facts</td>\n",
       "      <td>0.755102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>high school biology</td>\n",
       "      <td>0.750842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>high school chemistry</td>\n",
       "      <td>0.760204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>high school computer science</td>\n",
       "      <td>0.775510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>high school european history</td>\n",
       "      <td>0.721519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>high school geography</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>high school government and politics</td>\n",
       "      <td>0.762162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>high school macroeconomics</td>\n",
       "      <td>0.771654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>high school mathematics</td>\n",
       "      <td>0.731061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>high school microeconomics</td>\n",
       "      <td>0.738197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>high school physics</td>\n",
       "      <td>0.751678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>high school psychology</td>\n",
       "      <td>0.755639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>high school statistics</td>\n",
       "      <td>0.704762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>high school us history</td>\n",
       "      <td>0.823232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>high school world history</td>\n",
       "      <td>0.790179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>human aging</td>\n",
       "      <td>0.819444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>human sexuality</td>\n",
       "      <td>0.728682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>international law</td>\n",
       "      <td>0.692982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>jurisprudence</td>\n",
       "      <td>0.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>logical fallacies</td>\n",
       "      <td>0.746753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>machine learning</td>\n",
       "      <td>0.737864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>management</td>\n",
       "      <td>0.715686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>marketing</td>\n",
       "      <td>0.807860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>medical genetics</td>\n",
       "      <td>0.793814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>0.772069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>moral disputes</td>\n",
       "      <td>0.790274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>moral scenarios</td>\n",
       "      <td>0.781547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>nutrition</td>\n",
       "      <td>0.791246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>philosophy</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>prehistory</td>\n",
       "      <td>0.798701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>professional accounting</td>\n",
       "      <td>0.742647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>professional law</td>\n",
       "      <td>0.761074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>professional medicine</td>\n",
       "      <td>0.728302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>professional psychology</td>\n",
       "      <td>0.766610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>public relations</td>\n",
       "      <td>0.783019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>security studies</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>sociology</td>\n",
       "      <td>0.758974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>us foreign policy</td>\n",
       "      <td>0.778947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>virology</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>world religions</td>\n",
       "      <td>0.796407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                subject   correct\n",
       "0                      abstract algebra  0.736842\n",
       "1                               anatomy  0.775194\n",
       "2                             astronomy  0.750000\n",
       "3                       business ethics  0.734694\n",
       "4                    clinical knowledge  0.791506\n",
       "5                       college biology  0.820144\n",
       "6                     college chemistry  0.750000\n",
       "7              college computer science  0.752577\n",
       "8                   college mathematics  0.777778\n",
       "9                      college medicine  0.732143\n",
       "10                      college physics  0.785714\n",
       "11                    computer security  0.810526\n",
       "12                   conceptual physics  0.774336\n",
       "13                         econometrics  0.803571\n",
       "14               electrical engineering  0.780142\n",
       "15               elementary mathematics  0.765668\n",
       "16                         formal logic  0.788991\n",
       "17                         global facts  0.755102\n",
       "18                  high school biology  0.750842\n",
       "19                high school chemistry  0.760204\n",
       "20         high school computer science  0.775510\n",
       "21         high school european history  0.721519\n",
       "22                high school geography  0.733333\n",
       "23  high school government and politics  0.762162\n",
       "24           high school macroeconomics  0.771654\n",
       "25              high school mathematics  0.731061\n",
       "26           high school microeconomics  0.738197\n",
       "27                  high school physics  0.751678\n",
       "28               high school psychology  0.755639\n",
       "29               high school statistics  0.704762\n",
       "30               high school us history  0.823232\n",
       "31            high school world history  0.790179\n",
       "32                          human aging  0.819444\n",
       "33                      human sexuality  0.728682\n",
       "34                    international law  0.692982\n",
       "35                        jurisprudence  0.794118\n",
       "36                    logical fallacies  0.746753\n",
       "37                     machine learning  0.737864\n",
       "38                           management  0.715686\n",
       "39                            marketing  0.807860\n",
       "40                     medical genetics  0.793814\n",
       "41                        miscellaneous  0.772069\n",
       "42                       moral disputes  0.790274\n",
       "43                      moral scenarios  0.781547\n",
       "44                            nutrition  0.791246\n",
       "45                           philosophy  0.766667\n",
       "46                           prehistory  0.798701\n",
       "47              professional accounting  0.742647\n",
       "48                     professional law  0.761074\n",
       "49                professional medicine  0.728302\n",
       "50              professional psychology  0.766610\n",
       "51                     public relations  0.783019\n",
       "52                     security studies  0.787879\n",
       "53                            sociology  0.758974\n",
       "54                    us foreign policy  0.778947\n",
       "55                             virology  0.814815\n",
       "56                      world religions  0.796407"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_correct_percentage_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "380d4ae2-5ca5-41c1-beee-76ddc825b967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['college chemistry',\n",
       " 'college computer science',\n",
       " 'high school geography',\n",
       " 'moral disputes']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_difference_x_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "657c9919-5db4-4cfc-aaf4-d2af6613cddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['college chemistry',\n",
       " 'college computer science',\n",
       " 'computer security',\n",
       " 'medical genetics',\n",
       " 'moral disputes',\n",
       " 'moral scenarios']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_difference_y_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd28dd-07a3-40c9-8121-3262a387d17e",
   "metadata": {},
   "source": [
    "Let's see for subject x, as we can see we have for subject x we dont have any unbalance subject compared to the others, because if we look at the difference of x with respect to y and z there is not subject that is present in both, which mean it is x and y that are at fault in those cases. Let's create enough data to match the average differences bewteen subject less than 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a4ff14c-d829-455d-95b5-5e59524975cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(subject_difference_x_y).intersection(set(subject_difference_x_z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84837719-99ce-4bd2-a451-ac70472f598a",
   "metadata": {},
   "source": [
    "For LM y, we need to create more data for moral scenarios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c65587a7-32a6-4bd1-a716-db37341dfd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'moral scenarios'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imbalance_subject = set(subject_difference_x_y).intersection(set(subject_difference_y_z))\n",
    "imbalance_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2933c31-611b-4c62-a6a4-b4f278dc90f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'college chemistry', 'college computer science', 'moral disputes'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imbalance_subject = set(subject_difference_x_z).intersection(set(subject_difference_y_z))\n",
    "imbalance_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "affc3746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b2f61-0529-4b6d-a3a7-af786a4d79ae",
   "metadata": {},
   "source": [
    "## Task 2 (26 points): What do you mean A > D > B > C...?\n",
    "\n",
    "Nice work! Having successfully inspected, cleaned, and rebalanced the provided data, you head over to director of the government's NEUTRALITY project. Ms. Sakota is happy with your work so far, but worried that the sloppy intern might have done more undetected damage. To be sure, she orders a new set of evaluations of all models on both MMLU and another dataset.\n",
    "\n",
    "After cleaning up and rebalancing, you are left with the concatenated score files in the second folder `task_2`:\n",
    "```\n",
    "task_2/\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ lm_scores_mmlu.csv\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ lm_scores_other.csv\n",
    "```\n",
    "\n",
    "Each has a new column called `model_name`, which is one of `X, Y` or `Z`.\n",
    "\n",
    "\n",
    "\n",
    "_NOTE: **only** use data from `task_2` and `task_2_5` for this assignment! The values in `lm_scores_mmlu.csv` will NOT be the same as the dataframes you finished in task 1. This is due to \"randomness\" or \"temperature\" in language model inference. This can slightly shift around generative results. (Conveniently: it also ensures any mistakes made in Task 1 don't propogate further ;) )_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a889a76b-e034-4d2f-929e-0ef1f250a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROVIDED CODE\n",
    "df_mmlu = pd.read_csv('ada-2024-homework-1-5ds/task_2/lm_scores_mmlu.csv')\n",
    "df_other = pd.read_csv('ada-2024-homework-1-5ds/task_2/lm_scores_other.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31edde3-cc91-4d08-81c7-b5e98cf0ff9c",
   "metadata": {},
   "source": [
    "### 2.1 (4 pt)\n",
    "\n",
    "Let's explore the new results:\n",
    "\n",
    "A. Compute the mean accuracy and standard errors of each model on both datasets and print the results.\n",
    "\n",
    "B. Then, show your results in a bar plot using standard errors with a 95% confidence interval around the mean. Make sure the plot is easy to read and well annotated.\n",
    "\n",
    "C. /Discuss:/ the plot you created: (i) can you say that one of the models is the best? (ii) is there anything that seems odd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "534bc2e4-6e75-48a4-8ed9-9f6a9a834c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "      <th>subject</th>\n",
       "      <th>correct</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>Find the degree for the given field extension ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the i...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>C</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>Find all zeros in the indicated finite field o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,1</td>\n",
       "      <td>0,4</td>\n",
       "      <td>D</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>Statement 1 | A factor group of a non-Abelian ...</td>\n",
       "      <td>True, True</td>\n",
       "      <td>False, False</td>\n",
       "      <td>True, False</td>\n",
       "      <td>False, True</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>7</td>\n",
       "      <td>Statement 1 | A ring homomorphism is one to on...</td>\n",
       "      <td>True, True</td>\n",
       "      <td>False, False</td>\n",
       "      <td>True, False</td>\n",
       "      <td>False, True</td>\n",
       "      <td>D</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35083</th>\n",
       "      <td>A</td>\n",
       "      <td>14037</td>\n",
       "      <td>What has been a central focus of religious tra...</td>\n",
       "      <td>Peace and harmony</td>\n",
       "      <td>Power and influence</td>\n",
       "      <td>Truth and love</td>\n",
       "      <td>Wisdom and ethics</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>True</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35084</th>\n",
       "      <td>C</td>\n",
       "      <td>14038</td>\n",
       "      <td>To whom did ordinary folk appeal during a dro...</td>\n",
       "      <td>The Buddha</td>\n",
       "      <td>Laozi</td>\n",
       "      <td>The Queen Mother of the West</td>\n",
       "      <td>Confucius</td>\n",
       "      <td>C</td>\n",
       "      <td>world religions</td>\n",
       "      <td>True</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35085</th>\n",
       "      <td>B</td>\n",
       "      <td>14039</td>\n",
       "      <td>The theological term homoousios means which o...</td>\n",
       "      <td>of a similar substance</td>\n",
       "      <td>of the same substance</td>\n",
       "      <td>of like substance</td>\n",
       "      <td>of human substance</td>\n",
       "      <td>B</td>\n",
       "      <td>world religions</td>\n",
       "      <td>True</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35086</th>\n",
       "      <td>B</td>\n",
       "      <td>14040</td>\n",
       "      <td>According to the Japanese origin myth, who giv...</td>\n",
       "      <td>Es</td>\n",
       "      <td>Izanagi</td>\n",
       "      <td>Izanami</td>\n",
       "      <td>Kami</td>\n",
       "      <td>B</td>\n",
       "      <td>world religions</td>\n",
       "      <td>True</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35087</th>\n",
       "      <td>A</td>\n",
       "      <td>14041</td>\n",
       "      <td>The numen of Augustus referred to which of th...</td>\n",
       "      <td>Divine power</td>\n",
       "      <td>Sexual virility</td>\n",
       "      <td>Military acumen</td>\n",
       "      <td>Philosophical intellect</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>True</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35088 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  question_id                                           question  \\\n",
       "0          B            0  Find the degree for the given field extension ...   \n",
       "1          C            1  Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the i...   \n",
       "2          D            2  Find all zeros in the indicated finite field o...   \n",
       "3          B            3  Statement 1 | A factor group of a non-Abelian ...   \n",
       "4          D            7  Statement 1 | A ring homomorphism is one to on...   \n",
       "...      ...          ...                                                ...   \n",
       "35083      A        14037  What has been a central focus of religious tra...   \n",
       "35084      C        14038   To whom did ordinary folk appeal during a dro...   \n",
       "35085      B        14039   The theological term homoousios means which o...   \n",
       "35086      B        14040  According to the Japanese origin myth, who giv...   \n",
       "35087      A        14041   The numen of Augustus referred to which of th...   \n",
       "\n",
       "                            A                      B  \\\n",
       "0                           0                      4   \n",
       "1                           8                      2   \n",
       "2                           0                      1   \n",
       "3                  True, True           False, False   \n",
       "4                  True, True           False, False   \n",
       "...                       ...                    ...   \n",
       "35083       Peace and harmony    Power and influence   \n",
       "35084              The Buddha                  Laozi   \n",
       "35085  of a similar substance  of the same substance   \n",
       "35086                      Es                Izanagi   \n",
       "35087            Divine power        Sexual virility   \n",
       "\n",
       "                                  C                        D answer  \\\n",
       "0                                 2                        6      B   \n",
       "1                                24                      120      C   \n",
       "2                               0,1                      0,4      D   \n",
       "3                       True, False              False, True      B   \n",
       "4                       True, False              False, True      D   \n",
       "...                             ...                      ...    ...   \n",
       "35083                Truth and love        Wisdom and ethics      A   \n",
       "35084  The Queen Mother of the West                Confucius      C   \n",
       "35085             of like substance       of human substance      B   \n",
       "35086                       Izanami                     Kami      B   \n",
       "35087               Military acumen  Philosophical intellect      A   \n",
       "\n",
       "                subject  correct model_name  \n",
       "0      abstract algebra     True          X  \n",
       "1      abstract algebra     True          X  \n",
       "2      abstract algebra     True          X  \n",
       "3      abstract algebra     True          X  \n",
       "4      abstract algebra     True          X  \n",
       "...                 ...      ...        ...  \n",
       "35083   world religions     True          Z  \n",
       "35084   world religions     True          Z  \n",
       "35085   world religions     True          Z  \n",
       "35086   world religions     True          Z  \n",
       "35087   world religions     True          Z  \n",
       "\n",
       "[35088 rows x 11 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mmlu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56fe8cca-acd1-4f5e-a938-e8d3a850f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52e5d2c6-ec19-4f0b-af3c-9644d7820692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">X</th>\n",
       "      <th>mmlu</th>\n",
       "      <td>0.743588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.787976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Y</th>\n",
       "      <th>mmlu</th>\n",
       "      <td>0.761542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.720936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Z</th>\n",
       "      <th>mmlu</th>\n",
       "      <td>0.655951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.671721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean\n",
       "model_name dataset          \n",
       "X          mmlu     0.743588\n",
       "           other    0.787976\n",
       "Y          mmlu     0.761542\n",
       "           other    0.720936\n",
       "Z          mmlu     0.655951\n",
       "           other    0.671721"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mmlu['dataset'] = 'mmlu'\n",
    "df_other['dataset'] = 'other'\n",
    "\n",
    "combined_dataset = pd.concat([df_mmlu, df_other])\n",
    "combined_dataset.groupby(['model_name', 'dataset']).aggregate({'correct' : 'mean'}).rename(columns={'correct' : 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a991fa7f-d1d4-44bf-851f-2445eb8c4b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">X</th>\n",
       "      <th>mmlu</th>\n",
       "      <td>0.004038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.006668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Y</th>\n",
       "      <th>mmlu</th>\n",
       "      <td>0.003941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.007317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Z</th>\n",
       "      <th>mmlu</th>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.007660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sem\n",
       "model_name dataset          \n",
       "X          mmlu     0.004038\n",
       "           other    0.006668\n",
       "Y          mmlu     0.003941\n",
       "           other    0.007317\n",
       "Z          mmlu     0.004393\n",
       "           other    0.007660"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset.groupby(['model_name', 'dataset']).aggregate({'correct' : 'sem'}).rename(columns={'correct' : 'sem'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee868a6a-5311-4d5d-b4d0-6a5e82013c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "axes = sns.barplot(combined_dataset, x = 'model_name', y = 'correct', hue=\"dataset\", estimator='mean', errorbar=('ci', 95), palette = 'Set1')\n",
    "# Adding annotations\n",
    "for container in axes.containers:\n",
    "    # Optional: you can filter the containers for the bars if there are other objects like error bars\n",
    "    axes.bar_label(container, fmt='%.2f', padding=3)\n",
    "plt.ylabel('mean')\n",
    "\n",
    "plt.title('Mean comparison with 95% confidence interval between the 2 datasets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c9fbfe",
   "metadata": {},
   "source": [
    "C. /Discuss:/\n",
    "We can't say for sure which model is the best between model X and model Y since the 2 models mean confidence interval intersect each other for both dataset.\n",
    "Model z seems far less efficient, which is odd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee0ec62-f2d1-4bae-a6f6-221320d602cb",
   "metadata": {},
   "source": [
    "### 2.2 (5 pt)\n",
    "\n",
    "Ms. Sakota has assured you that both datasets contain questions of similar difficulty, so, what could be going on here?\n",
    "\n",
    "A. What is the distribution of correct answers (A, B, C, D) for each dataset? Create a bar chart to visualize this.\n",
    "\n",
    "B. Perform a chi-square test at $\\alpha = 0.05$, of independence to determine if there's a significant difference in the distribution of correct answers between the two datasets. What do you conclude?\n",
    "\n",
    "**hints**:\n",
    "- for (A), keep in mind that df_mmlu and df_other contain the results of all models, i.e., the `question_id` column is duplicated.\n",
    "- for (A), take care to clearly annotate the bar chart, e.g., title, y-label, legend.\n",
    "- for (B), clearly state the null hypothesis and alternative hypothesis\n",
    "- use the `chi2_contingency` function from `scipy.stats`\n",
    "- format your results from answer (A) as a 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ff67e89-fc2d-4893-82df-f58d8b9b37eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a9c847e-49c3-449e-815f-e52ce0f95fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='answer', ylabel='correct'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGwCAYAAABIC3rIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/hElEQVR4nO3de1QV9f7/8dfmKooblOSWqJSpUN5N3Sc1LyQaubKoo2VpivrV0L5IqXmOmWlFWV7T9OQNO2mp3dNESROPSaJ0UFMz66DY0Q39UtihCQj8/mgxX3d2E4GNzvOx1qzY8/nMZ79nT8Srmc/MtpSXl5cLAADAxNxcXQAAAICrEYgAAIDpEYgAAIDpEYgAAIDpEYgAAIDpEYgAAIDpEYgAAIDpebi6gKtBWVmZTp48qfr168tisbi6HAAA8CeUl5frxx9/VGhoqNzcfv8cEIHoTzh58qTCwsJcXQYAAKiEEydOqHHjxr/bh0D0J9SvX1/Szx+o1Wp1cTUAAODPcDgcCgsLM/6O/x4C0Z9QcZnMarUSiAAAuMr8mekuTKoGAACmRyACAACmRyACAACmxxyiKlRaWqqSkhJXl3HN8fT0lLu7u6vLAABcwwhEVaC8vFx2u135+fmuLuWa5e/vr+DgYJ4DBQCoFgSiKlARhgIDA1W3bl3+aFeh8vJynTt3Tnl5eZKkkJAQF1cEALgWEYiuUGlpqRGGAgICXF3ONcnHx0eSlJeXp8DAQC6fAQCqHJOqr1DFnKG6deu6uJJrW8XnyxwtAEB1IBBVES6TVS8+XwBAdSIQAQAA0yMQAQAA0yMQXUV69uyphIQEV5cBAMA1h0B0jdq+fbssFkuNPxtp+vTpateuXY2+JwAAV4pABAAATI9AVEudPXtWQ4cOla+vr0JCQjR79myn9n/+85/q1KmT6tevr+DgYD344IPGwwuPHTumXr16SZIaNGggi8WiRx55RJKUkpKibt26yd/fXwEBAbrrrrv07bffGuMWFxdr3LhxCgkJUZ06ddS0aVMlJSUZ7fn5+Ro5cqQaNWokq9Wq3r17a9++fZKk5ORkPfPMM9q3b58sFossFouSk5Or8VMCAKBq8GDGWmrixIlKS0vTBx98oMDAQP3tb3/TF198YVyOKikp0cyZM9WyZUvl5eUpMTFRjzzyiD7++GOFhYXpnXfeUWxsrI4cOSKr1Wo83PDs2bNKTExUmzZtVFhYqGnTpumee+5RVlaW3NzctGDBAn344Ydat26dmjRpohMnTujEiRNGXffff798fHy0adMm+fn56R//+If69Omjr7/+WoMGDdKXX36plJQUffLJJ5IkPz+/Gv/sAKCq7e3U2dUlXLFOezNcXUKtRiCqhQoLC7V8+XK98cYb6tOnjyRp1apVaty4sdFnxIgRxs833HCDFixYoFtvvVWFhYXy9fVVw4YNJUmBgYHy9/c3+sbGxjq914oVK9SoUSMdOnRIt9xyi3JycnTTTTepW7duslgsatq0qdF3586dysjIUF5enry9vSVJL7/8st5//329/fbbGj16tHx9feXh4aHg4OAq/1wAAKguXDKrhb799lsVFxerS5cuxrqGDRuqZcuWxuvMzEwNGDBATZo0Uf369XX77bdLknJycn537KNHj+qBBx7QDTfcIKvVqmbNmjlt98gjjygrK0stW7bUY489pi1bthjb7tu3T4WFhQoICJCvr6+xZGdnO112AwDgasMZoqvQ2bNnFR0drejoaK1evVqNGjVSTk6OoqOjVVxc/LvbDhgwQE2bNtXSpUsVGhqqsrIy3XLLLcZ2HTp0UHZ2tjZt2qRPPvlEf/3rXxUVFaW3335bhYWFCgkJ0fbt2y8Z9+KzUAAAXG0IRLXQjTfeKE9PT+3evVtNmjSRJJ05c0Zff/21br/9dn311Vf64Ycf9MILLygsLEyStHfvXqcxvLy8JP385bMVfvjhBx05ckRLly5V9+7dJf18GeyXrFarBg0apEGDBum+++5Tv379dPr0aXXo0EF2u10eHh7GmaVf8vLycnpPAACuBgSiWsjX11dxcXGaOHGiAgICFBgYqL///e9yc/v5CmeTJk3k5eWlV155RWPGjNGXX36pmTNnOo3RtGlTWSwWbdiwQXfeead8fHzUoEEDBQQE6LXXXlNISIhycnL05JNPOm03Z84chYSEqH379nJzc9P69esVHBwsf39/RUVFyWazaeDAgZo1a5ZatGihkydPauPGjbrnnnvUqVMnNWvWTNnZ2crKylLjxo1Vv359Y74RAAC1lUvnEJWWluqpp55SeHi4fHx8dOONN2rmzJkqLy83+pSXl2vatGkKCQmRj4+PoqKidPToUadxTp8+rSFDhshqtcrf319xcXEqLCx06rN//351795dderUUVhYmGbNmlUj+1hZL730krp3764BAwYoKipK3bp1U8eOHSVJjRo1UnJystavX6/IyEi98MILevnll522v/766/XMM8/oySefVFBQkMaNGyc3Nze99dZbyszM1C233KIJEybopZdectqufv36mjVrljp16qRbb71Vx44d08cffyw3NzdZLBZ9/PHH6tGjh4YPH64WLVpo8ODBOn78uIKCgiT9PGm7X79+6tWrlxo1aqQ333yzZj4wAACugKX84vRRw55//nnNmTNHq1at0s0336y9e/dq+PDheu655/TYY49Jkl588UUlJSVp1apVCg8P11NPPaUDBw7o0KFDqlOnjiSpf//+OnXqlP7xj3+opKREw4cP16233qo1a9ZIkhwOh1q0aKGoqChNmTJFBw4c0IgRIzRv3jyNHj36D+t0OBzy8/NTQUGBrFarU9v58+eVnZ2t8PBwox5UPT5nAK7EbfdXp9/7+/1LLr1ktmvXLt19992KiYmRJDVr1kxvvvmmMjJ+Pmjl5eWaN2+epk6dqrvvvluS9PrrrysoKEjvv/++Bg8erMOHDyslJUV79uxRp06dJEmvvPKK7rzzTr388ssKDQ3V6tWrVVxcrBUrVsjLy0s333yzsrKyNGfOnF8NREVFRSoqKjJeOxyO6v4oAACAC7n0ktlf/vIXbd26VV9//bWkn2/r3rlzp/r37y9Jys7Olt1uV1RUlLGNn5+funTpovT0dElSenq6/P39jTAkSVFRUXJzc9Pu3buNPj169DAmGktSdHS0jhw5ojNnzlxSV1JSkvz8/IylYuIyAAC4Nrn0DNGTTz4ph8OhVq1ayd3dXaWlpXruuec0ZMgQSZLdbpckY35KhaCgIKPNbrcrMDDQqd3Dw0MNGzZ06hMeHn7JGBVtDRo0cGqbMmWKEhMTjdcOh4NQBADANcylgWjdunVavXq11qxZY1zGSkhIUGhoqIYNG+ayury9vbkzCgAAE3FpIJo4caKefPJJDR48WJLUunVrHT9+XElJSRo2bJjx9Q+5ubkKCQkxtsvNzTW+0ys4ONj4UtMKFy5c0OnTp43tg4ODlZub69Sn4jVfMQEAAFw6h+jcuXPGs3UquLu7q6ysTJIUHh6u4OBgbd261Wh3OBzavXu3bDabJMlmsyk/P1+ZmZlGn23btqmsrMz46gubzaYdO3aopKTE6JOamqqWLVtecrkMAACYj0sD0YABA/Tcc89p48aNOnbsmN577z3NmTNH99xzjyTJYrEoISFBzz77rD788EMdOHBAQ4cOVWhoqAYOHChJioiIUL9+/TRq1ChlZGTos88+07hx4zR48GCFhoZKkh588EF5eXkpLi5OBw8e1Nq1azV//nyneUIAAMC8XHrJ7JVXXtFTTz2lRx99VHl5eQoNDdX//M//aNq0aUafSZMm6ezZsxo9erTy8/PVrVs3paSkOD2LZvXq1Ro3bpz69OkjNzc3xcbGasGCBUa7n5+ftmzZovj4eHXs2FHXXXedpk2b9qeeQQQAAK59Ln0w49WCBzNemZ49e6pdu3aaN29epcfgcwbgSjyY8ep01TyY8VpX079AZvyXHQCAquDSOUQAAAC1AYHIxHr27Knx48crISFBDRo0UFBQkJYuXaqzZ89q+PDhql+/vpo3b65NmzZJkrZv3y6LxaLNmzerffv28vHxUe/evZWXl6dNmzYpIiJCVqtVDz74oM6dO/eb72uxWPT+++87rfP391dycnI17i0AAL+NQGRyq1at0nXXXaeMjAyNHz9eY8eO1f3336+//OUv+uKLL9S3b189/PDDTgFn+vTpWrhwoXbt2qUTJ07or3/9q+bNm6c1a9Zo48aN2rJli1555RUX7hUAAJeHQGRybdu21dSpU3XTTTdpypQpqlOnjq677jqNGjVKN910k6ZNm6YffvhB+/fvN7Z59tlnddttt6l9+/aKi4tTWlqaFi9erPbt26t79+6677779Omnn7pwrwAAuDwEIpNr06aN8bO7u7sCAgLUunVrY13Fd75d/DTwi7cJCgpS3bp1dcMNNzit++XTwwEAqM0IRCbn6enp9NpisTits1gskmQ8PfyX2/yyf8W6i/v/ksVi0S+f9nDxU8QBAKhpBCLUuEaNGunUqVPG66NHj/7uJGwAAKobzyFCjevdu7cWLlwom82m0tJSTZ48+ZKzTAAA1CTOEKHGzZ49W2FhYerevbsefPBBPfHEE6pbt66rywIAmBhf3fEn8NUdrsfnDMCV+OqOq9PlfHUHZ4gAAIDpEYgAAIDpEYgAAIDpEYgAAIDpEYgAAIDpEYgAAIDpEYgAAIDpEYgAAIDpEYgAAIDpEYhw2Xr27KmEhARXlwEAQJXhy12rUb+n1tbo+6XMHFSl423fvl29evXSmTNn5O/vX6VjAwBQm3CGCLVCcXGxq0sAAJgYgcjkioqK9NhjjykwMFB16tRRt27dtGfPHh07dky9evWSJDVo0EAWi0WPPPKIsV1ZWZkmTZqkhg0bKjg4WNOnT3caNz8/XyNHjlSjRo1ktVrVu3dv7du3z2ifPn262rVrp2XLlvGFrQAAlyMQmdykSZP0zjvvaNWqVfriiy/UvHlzRUdHq379+nrnnXckSUeOHNGpU6c0f/58Y7tVq1apXr162r17t2bNmqUZM2YoNTXVaL///vuVl5enTZs2KTMzUx06dFCfPn10+vRpo88333yjd955R++++66ysrJqbJ8BAPgl5hCZ2NmzZ7V48WIlJyerf//+kqSlS5cqNTVVK1as0K233ipJCgwMvGQOUZs2bfT0009Lkm666SYtXLhQW7du1R133KGdO3cqIyNDeXl58vb2liS9/PLLev/99/X2229r9OjRkn6+TPb666+rUaNGNbTHAAD8OgKRiX377bcqKSnRbbfdZqzz9PRU586ddfjwYSMQ/Zo2bdo4vQ4JCVFeXp4kad++fSosLFRAQIBTn59++knffvut8bpp06aEIQBArUAgQqV4eno6vbZYLCorK5MkFRYWKiQkRNu3b79ku4vPNNWrV686SwSq1d5OnV1dwhXrtDfD1SUAtQaByMRuvPFGeXl56bPPPlPTpk0lSSUlJdqzZ48SEhLk5eUlSSotLb2scTt06CC73S4PDw81a9asqssGAKDKManaxOrVq6exY8dq4sSJSklJ0aFDhzRq1CidO3dOcXFxatq0qSwWizZs2KDvv/9ehYWFf2rcqKgo2Ww2DRw4UFu2bNGxY8e0a9cu/f3vf9fevXurea8AALh8BCKTe+GFFxQbG6uHH35YHTp00DfffKPNmzerQYMGuv766/XMM8/oySefVFBQkMaNG/enxrRYLPr444/Vo0cPDR8+XC1atNDgwYN1/PhxBQUFVfMeAQBw+Szl5eXlrnrzZs2a6fjx45esf/TRR7Vo0SKdP39ejz/+uN566y0VFRUpOjpar776qtMf1ZycHI0dO1affvqpfH19NWzYMCUlJcnD4/+uBm7fvl2JiYk6ePCgwsLCNHXqVKdn6vwRh8MhPz8/FRQUyGq1OrWdP39e2dnZPEunmvE5o7ZhDpG5cLyvTr/39/uXXHqGaM+ePTp16pSxVDzH5v7775ckTZgwQR999JHWr1+vtLQ0nTx5Uvfee6+xfWlpqWJiYlRcXKxdu3Zp1apVSk5O1rRp04w+2dnZiomJUa9evZSVlaWEhASNHDlSmzdvrtmdBQAAtZZLJ1X/8pbrF154QTfeeKNuv/12FRQUaPny5VqzZo169+4tSVq5cqUiIiL0+eefq2vXrtqyZYsOHTqkTz75REFBQWrXrp1mzpypyZMna/r06fLy8tKSJUsUHh6u2bNnS5IiIiK0c+dOzZ07V9HR0TW+zwAAoPapNXOIiouL9cYbb2jEiBGyWCzKzMxUSUmJoqKijD6tWrVSkyZNlJ6eLklKT09X69atnS6hRUdHy+Fw6ODBg0afi8eo6FMxxq8pKiqSw+FwWgAAwLWr1gSi999/X/n5+cbcHrvdLi8vr0uekBwUFCS73W70+eUk3YrXf9TH4XDop59++tVakpKS5OfnZyxhYWFXunsAAKAWqzWBaPny5erfv79CQ0NdXYqmTJmigoICYzlx4sQfbuPCuemmwOcLAKhOteLBjMePH9cnn3yid99911gXHBys4uJi5efnO50lys3NVXBwsNEnI8N51nxubq7RVvHPinUX97FarfLx8fnVery9vY3v4PojFU9sPnfu3G+Ohyt37tw5SZc+IRsAgKpQKwLRypUrFRgYqJiYGGNdx44d5enpqa1btyo2NlbSz9+6npOTI5vNJkmy2Wx67rnnlJeXp8DAQElSamqqrFarIiMjjT4ff/yx0/ulpqYaY1wpd3d3+fv7G9/jVbduXVkslioZGz+fGTp37pzy8vLk7+8vd3d3V5cEALgGuTwQlZWVaeXKlRo2bJjTs4P8/PwUFxenxMRENWzYUFarVePHj5fNZlPXrl0lSX379lVkZKQefvhhzZo1S3a7XVOnTlV8fLxxhmfMmDFauHChJk2apBEjRmjbtm1at26dNm7cWGX7UHE2qiIUoer5+/sbnzMAAFXN5YHok08+UU5OjkaMGHFJ29y5c+Xm5qbY2FinBzNWcHd314YNGzR27FjZbDbVq1dPw4YN04wZM4w+4eHh2rhxoyZMmKD58+ercePGWrZsWZXecm+xWBQSEqLAwECVlJRU2bj4maenJ2eGAADVyqVPqr5aXM6TLgGYA08uNheO99XpqnlSNQAAQG1AIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKbn4eoCgGvF3k6dXV3CFeu0N8PVJQCAS3CGCAAAmB6BCAAAmB6BCAAAmB6BCAAAmB6BCAAAmB6BCAAAmJ7LA9F///tfPfTQQwoICJCPj49at26tvXv3Gu3l5eWaNm2aQkJC5OPjo6ioKB09etRpjNOnT2vIkCGyWq3y9/dXXFycCgsLnfrs379f3bt3V506dRQWFqZZs2bVyP4BAIDaz6WB6MyZM7rtttvk6empTZs26dChQ5o9e7YaNGhg9Jk1a5YWLFigJUuWaPfu3apXr56io6N1/vx5o8+QIUN08OBBpaamasOGDdqxY4dGjx5ttDscDvXt21dNmzZVZmamXnrpJU2fPl2vvfZaje4vAAConVz6YMYXX3xRYWFhWrlypbEuPDzc+Lm8vFzz5s3T1KlTdffdd0uSXn/9dQUFBen999/X4MGDdfjwYaWkpGjPnj3q1KmTJOmVV17RnXfeqZdfflmhoaFavXq1iouLtWLFCnl5eenmm29WVlaW5syZ4xScAACAObn0DNGHH36oTp066f7771dgYKDat2+vpUuXGu3Z2dmy2+2Kiooy1vn5+alLly5KT0+XJKWnp8vf398IQ5IUFRUlNzc37d692+jTo0cPeXl5GX2io6N15MgRnTlz5pK6ioqK5HA4nBYAAHDtcmkg+s9//qPFixfrpptu0ubNmzV27Fg99thjWrVqlSTJbrdLkoKCgpy2CwoKMtrsdrsCAwOd2j08PNSwYUOnPr82xsXvcbGkpCT5+fkZS1hYWBXsLQAAqK1cGojKysrUoUMHPf/882rfvr1Gjx6tUaNGacmSJa4sS1OmTFFBQYGxnDhxwqX1AACA6uXSQBQSEqLIyEindREREcrJyZEkBQcHS5Jyc3Od+uTm5hptwcHBysvLc2q/cOGCTp8+7dTn18a4+D0u5u3tLavV6rQAAIBrl0sD0W233aYjR444rfv666/VtGlTST9PsA4ODtbWrVuNdofDod27d8tms0mSbDab8vPzlZmZafTZtm2bysrK1KVLF6PPjh07VFJSYvRJTU1Vy5Ytne5oAwAA5uTSQDRhwgR9/vnnev755/XNN99ozZo1eu211xQfHy9JslgsSkhI0LPPPqsPP/xQBw4c0NChQxUaGqqBAwdK+vmMUr9+/TRq1ChlZGTos88+07hx4zR48GCFhoZKkh588EF5eXkpLi5OBw8e1Nq1azV//nwlJia6atcBAEAt4tLb7m+99Va99957mjJlimbMmKHw8HDNmzdPQ4YMMfpMmjRJZ8+e1ejRo5Wfn69u3bopJSVFderUMfqsXr1a48aNU58+feTm5qbY2FgtWLDAaPfz89OWLVsUHx+vjh076rrrrtO0adO45R4AAEiSLOXl5eWuLqK2czgc8vPzU0FBAfOJ8Jv2durs6hKuWKe9Ga4u4arB8TYXjvfV6XL+frv8qzsAAABcjUAEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMz6WBaPr06bJYLE5Lq1atjPbz588rPj5eAQEB8vX1VWxsrHJzc53GyMnJUUxMjOrWravAwEBNnDhRFy5ccOqzfft2dejQQd7e3mrevLmSk5NrYvcAAMBVwuVniG6++WadOnXKWHbu3Gm0TZgwQR999JHWr1+vtLQ0nTx5Uvfee6/RXlpaqpiYGBUXF2vXrl1atWqVkpOTNW3aNKNPdna2YmJi1KtXL2VlZSkhIUEjR47U5s2ba3Q/AQBA7eXh8gI8PBQcHHzJ+oKCAi1fvlxr1qxR7969JUkrV65URESEPv/8c3Xt2lVbtmzRoUOH9MknnygoKEjt2rXTzJkzNXnyZE2fPl1eXl5asmSJwsPDNXv2bElSRESEdu7cqblz5yo6OrpG9xUAANROLj9DdPToUYWGhuqGG27QkCFDlJOTI0nKzMxUSUmJoqKijL6tWrVSkyZNlJ6eLklKT09X69atFRQUZPSJjo6Ww+HQwYMHjT4Xj1HRp2KMX1NUVCSHw+G0AACAa5dLA1GXLl2UnJyslJQULV68WNnZ2erevbt+/PFH2e12eXl5yd/f32mboKAg2e12SZLdbncKQxXtFW2/18fhcOinn3761bqSkpLk5+dnLGFhYVWxuwAAoJZy6SWz/v37Gz+3adNGXbp0UdOmTbVu3Tr5+Pi4rK4pU6YoMTHReO1wOAhFAABcw1x+yexi/v7+atGihb755hsFBweruLhY+fn5Tn1yc3ONOUfBwcGX3HVW8fqP+lit1t8MXd7e3rJarU4LAAC4dtWqQFRYWKhvv/1WISEh6tixozw9PbV161aj/ciRI8rJyZHNZpMk2Ww2HThwQHl5eUaf1NRUWa1WRUZGGn0uHqOiT8UYAAAALg1ETzzxhNLS0nTs2DHt2rVL99xzj9zd3fXAAw/Iz89PcXFxSkxM1KeffqrMzEwNHz5cNptNXbt2lST17dtXkZGRevjhh7Vv3z5t3rxZU6dOVXx8vLy9vSVJY8aM0X/+8x9NmjRJX331lV599VWtW7dOEyZMcOWuAwCAWsSlc4i+++47PfDAA/rhhx/UqFEjdevWTZ9//rkaNWokSZo7d67c3NwUGxuroqIiRUdH69VXXzW2d3d314YNGzR27FjZbDbVq1dPw4YN04wZM4w+4eHh2rhxoyZMmKD58+ercePGWrZsGbfcAwAAg6W8vLzc1UXUdg6HQ35+fiooKGA+EX7T3k6dXV3CFeu0N8PVJVw1ON7mwvG+Ol3O3+9KXTJ7/fXXVVRUdMn64uJivf7665UZEgAAwGUqFYiGDx+ugoKCS9b/+OOPGj58+BUXBQAAUJMqFYjKy8tlsVguWf/dd9/Jz8/viosCAACoSZc1qbp9+/bGt9L36dNHHh7/t3lpaamys7PVr1+/Ki8SAACgOl1WIBo4cKAkKSsrS9HR0fL19TXavLy81KxZM8XGxlZpgQAAANXtsgLR008/LUlq1qyZBg8ebDzrBwAA4GpWqTlEkZGRysrKumT97t27tXfv3iutCQAAoEZVKhDFx8frxIkTl6z/73//q/j4+CsuCgAAoCZVKhAdOnRIHTp0uGR9+/btdejQoSsuCgAAoCZVKhB5e3tf8g3yknTq1CmnO88AAACuBpUKRH379tWUKVOcHs6Yn5+vv/3tb7rjjjuqrDgAAICaUKnTOS+//LJ69Oihpk2bqn379pJ+vhU/KChI//znP6u0QAAAgOpWqUB0/fXXa//+/Vq9erX27dsnHx8fDR8+XA888IA8PT2rukYAAIBqVekJP/Xq1dPo0aOrshYAAACXqNQcIkn65z//qW7duik0NFTHjx+XJM2dO1cffPBBlRUHAABQEyoViBYvXqzExET1799fZ86cUWlpqSSpQYMGmjdvXlXWBwAAUO0qFYheeeUVLV26VH//+9+dbrPv1KmTDhw4UGXFAQAA1IRKBaLs7Gzj7rKLeXt76+zZs1dcFAAAQE2qVCAKDw//1e8yS0lJUURExJXWBAAAUKMqdZdZYmKi4uPjdf78eZWXlysjI0NvvvmmkpKStGzZsqquEQAAoFpVKhCNHDlSPj4+mjp1qs6dO6cHH3xQoaGhmj9/vgYPHlzVNQIAAFSryw5EFy5c0Jo1axQdHa0hQ4bo3LlzKiwsVGBgYHXUBwAAUO0uew6Rh4eHxowZo/Pnz0uS6tatSxgCAABXtUpNqu7cubP+/e9/V3UtAAAALlGpOUSPPvqoHn/8cX333Xfq2LGj6tWr59Tepk2bKikOAACgJlQqEFVMnH7ssceMdRaLReXl5bJYLMaTqwEAAK4GlQpE2dnZVV0HAACAy1x2ICopKVHv3r21YcMGHsIIAACuCZc9qdrT09O4wwwAAOBaUKm7zOLj4/Xiiy/qwoULVV0PAABAjavUHKI9e/Zo69at2rJli1q3bn3JXWbvvvtulRQHAABQEyoViPz9/RUbG1vVtQAAALhEpS6ZrVy58neXynjhhRdksViUkJBgrDt//rzi4+MVEBAgX19fxcbGKjc312m7nJwcxcTEGE/Mnjhx4iWX8rZv364OHTrI29tbzZs3V3JycqVqBAAA16ZKBaIK33//vXbu3KmdO3fq+++/r/Q4e/bs0T/+8Y9LHug4YcIEffTRR1q/fr3S0tJ08uRJ3XvvvUZ7aWmpYmJiVFxcrF27dmnVqlVKTk7WtGnTjD7Z2dmKiYlRr169lJWVpYSEBI0cOVKbN2+udL0AAODaUqlAdPbsWY0YMUIhISHq0aOHevToodDQUMXFxencuXOXNVZhYaGGDBmipUuXqkGDBsb6goICLV++XHPmzFHv3r3VsWNHrVy5Urt27dLnn38uSdqyZYsOHTqkN954Q+3atVP//v01c+ZMLVq0SMXFxZKkJUuWKDw8XLNnz1ZERITGjRun++67T3Pnzv3NmoqKiuRwOJwWAABw7apUIEpMTFRaWpo++ugj5efnKz8/Xx988IHS0tL0+OOPX9ZY8fHxiomJUVRUlNP6zMxMlZSUOK1v1aqVmjRpovT0dElSenq6WrduraCgIKNPdHS0HA6HDh48aPT55djR0dHGGL8mKSlJfn5+xhIWFnZZ+wQAAK4ulZpU/c477+jtt99Wz549jXV33nmnfHx89Ne//lWLFy/+U+O89dZb+uKLL7Rnz55L2ux2u7y8vOTv7++0PigoSHa73ehzcRiqaK9o+70+DodDP/30k3x8fC557ylTpigxMdF47XA4CEUAAFzDKhWIzp07d0nIkKTAwMA/fcnsxIkT+t///V+lpqaqTp06lSmj2nh7e8vb29vVZQAAgBpSqUtmNptNTz/9tNMTq3/66Sc988wzstlsf2qMzMxM5eXlqUOHDvLw8JCHh4fS0tK0YMECeXh4KCgoSMXFxcrPz3faLjc3V8HBwZKk4ODgS+46q3j9R32sVuuvnh0CAADmU6kzRPPmzVO/fv3UuHFjtW3bVpK0b98+eXt7a8uWLX9qjD59+ujAgQNO64YPH65WrVpp8uTJCgsLk6enp7Zu3Wo88+jIkSPKyckxQpfNZtNzzz2nvLw8BQYGSpJSU1NltVoVGRlp9Pn444+d3ic1NfVPBzcAAHDtq1Qgat26tY4eParVq1frq6++kiQ98MADGjJkyJ8+61K/fn3dcsstTuvq1aungIAAY31cXJwSExPVsGFDWa1WjR8/XjabTV27dpUk9e3bV5GRkXr44Yc1a9Ys2e12TZ06VfHx8cYlrzFjxmjhwoWaNGmSRowYoW3btmndunXauHFjZXYdAABcgyoViJKSkhQUFKRRo0Y5rV+xYoW+//57TZ48uUqKmzt3rtzc3BQbG6uioiJFR0fr1VdfNdrd3d21YcMGjR07VjabTfXq1dOwYcM0Y8YMo094eLg2btyoCRMmaP78+WrcuLGWLVum6OjoKqkRAABc/Szl5eXll7tRs2bNtGbNGv3lL39xWr97924NHjxY2dnZVVZgbeBwOOTn56eCggJZrVZXl4Naam+nzq4u4Yp12pvh6hKuGhxvc+F4X50u5+93pSZV2+12hYSEXLK+UaNGOnXqVGWGBAAAcJlKBaKwsDB99tlnl6z/7LPPFBoaesVFAQAA1KRKzSEaNWqUEhISVFJSot69e0uStm7dqkmTJl32k6oBAABcrVKBaOLEifrhhx/06KOPGt8ZVqdOHU2ePFlTpkyp0gIBAACqW6UCkcVi0YsvvqinnnpKhw8flo+Pj2666Sae7gwAAK5KlQpEFXx9fXXrrbdWVS0AAAAuUalJ1QAAANcSAhEAADA9AhEAADC9K5pDhN/Hk00BALg6cIYIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYHoEIAACYnksD0eLFi9WmTRtZrVZZrVbZbDZt2rTJaD9//rzi4+MVEBAgX19fxcbGKjc312mMnJwcxcTEqG7dugoMDNTEiRN14cIFpz7bt29Xhw4d5O3trebNmys5Obkmdg8AAFwlXBqIGjdurBdeeEGZmZnau3evevfurbvvvlsHDx6UJE2YMEEfffSR1q9fr7S0NJ08eVL33nuvsX1paaliYmJUXFysXbt2adWqVUpOTta0adOMPtnZ2YqJiVGvXr2UlZWlhIQEjRw5Ups3b67x/QUAALWTpby8vNzVRVysYcOGeumll3TfffepUaNGWrNmje677z5J0ldffaWIiAilp6era9eu2rRpk+666y6dPHlSQUFBkqQlS5Zo8uTJ+v777+Xl5aXJkydr48aN+vLLL433GDx4sPLz85WSkvKrNRQVFamoqMh47XA4FBYWpoKCAlmt1j+9L3s7da7MR1CrdNqb4eoSrhocb3PheJsLx/vq5HA45Ofn96f+fteaOUSlpaV66623dPbsWdlsNmVmZqqkpERRUVFGn1atWqlJkyZKT0+XJKWnp6t169ZGGJKk6OhoORwO4yxTenq60xgVfSrG+DVJSUny8/MzlrCwsKrcVQAAUMu4PBAdOHBAvr6+8vb21pgxY/Tee+8pMjJSdrtdXl5e8vf3d+ofFBQku90uSbLb7U5hqKK9ou33+jgcDv3000+/WtOUKVNUUFBgLCdOnKiKXQUAALWUh6sLaNmypbKyslRQUKC3335bw4YNU1pamktr8vb2lre3t0trAAAANcflgcjLy0vNmzeXJHXs2FF79uzR/PnzNWjQIBUXFys/P9/pLFFubq6Cg4MlScHBwcrIcL4mWnEX2sV9fnlnWm5urqxWq3x8fKprtwAAwFXE5ZfMfqmsrExFRUXq2LGjPD09tXXrVqPtyJEjysnJkc1mkyTZbDYdOHBAeXl5Rp/U1FRZrVZFRkYafS4eo6JPxRgAAAAuPUM0ZcoU9e/fX02aNNGPP/6oNWvWaPv27dq8ebP8/PwUFxenxMRENWzYUFarVePHj5fNZlPXrl0lSX379lVkZKQefvhhzZo1S3a7XVOnTlV8fLxxyWvMmDFauHChJk2apBEjRmjbtm1at26dNm7c6MpdBwAAtYhLA1FeXp6GDh2qU6dOyc/PT23atNHmzZt1xx13SJLmzp0rNzc3xcbGqqioSNHR0Xr11VeN7d3d3bVhwwaNHTtWNptN9erV07BhwzRjxgyjT3h4uDZu3KgJEyZo/vz5aty4sZYtW6bo6Oga318AAFA71brnENVGl/Mcg4vx3Apz4XibC8fbXDjeV6er8jlEAAAArkIgAgAApkcgAgAApkcgAgAApkcgAgAApkcgAgAApkcgAgAApkcgAgAApkcgAgAApkcgAgAApkcgAgAApkcgAgAApkcgAgAApkcgAgAApkcgAgAApufh6gJQu/V7aq2rS6gSKTMHuboEAEAtxhkiAABgegQiAABgegQiAABgeswhAmBgzhgAs+IMEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD2XBqKkpCTdeuutql+/vgIDAzVw4EAdOXLEqc/58+cVHx+vgIAA+fr6KjY2Vrm5uU59cnJyFBMTo7p16yowMFATJ07UhQsXnPps375dHTp0kLe3t5o3b67k5OTq3j0AAHCVcGkgSktLU3x8vD7//HOlpqaqpKREffv21dmzZ40+EyZM0EcffaT169crLS1NJ0+e1L333mu0l5aWKiYmRsXFxdq1a5dWrVql5ORkTZs2zeiTnZ2tmJgY9erVS1lZWUpISNDIkSO1efPmGt1fAABQO7n02+5TUlKcXicnJyswMFCZmZnq0aOHCgoKtHz5cq1Zs0a9e/eWJK1cuVIRERH6/PPP1bVrV23ZskWHDh3SJ598oqCgILVr104zZ87U5MmTNX36dHl5eWnJkiUKDw/X7NmzJUkRERHauXOn5s6dq+jo6BrfbwAAULvUqjlEBQUFkqSGDRtKkjIzM1VSUqKoqCijT6tWrdSkSROlp6dLktLT09W6dWsFBQUZfaKjo+VwOHTw4EGjz8VjVPSpGOOXioqK5HA4nBYAAHDtqjWBqKysTAkJCbrtttt0yy23SJLsdru8vLzk7+/v1DcoKEh2u93oc3EYqmivaPu9Pg6HQz/99NMltSQlJcnPz89YwsLCqmQfAQBA7VRrAlF8fLy+/PJLvfXWW64uRVOmTFFBQYGxnDhxwtUlAQCAauTSOUQVxo0bpw0bNmjHjh1q3LixsT44OFjFxcXKz893OkuUm5ur4OBgo09GRobTeBV3oV3c55d3puXm5spqtcrHx+eSery9veXt7V0l+wYAAGo/lwai8vJyjR8/Xu+99562b9+u8PBwp/aOHTvK09NTW7duVWxsrCTpyJEjysnJkc1mkyTZbDY999xzysvLU2BgoCQpNTVVVqtVkZGRRp+PP/7YaezU1FRjDAAwo35PrXV1CVUiZeYgV5eAa4BLA1F8fLzWrFmjDz74QPXr1zfm/Pj5+cnHx0d+fn6Ki4tTYmKiGjZsKKvVqvHjx8tms6lr166SpL59+yoyMlIPP/ywZs2aJbvdrqlTpyo+Pt44yzNmzBgtXLhQkyZN0ogRI7Rt2zatW7dOGzdudNm+AwCA2sOlc4gWL16sgoIC9ezZUyEhIcaydu3//V/L3Llzdddddyk2NlY9evRQcHCw3n33XaPd3d1dGzZskLu7u2w2mx566CENHTpUM2bMMPqEh4dr48aNSk1NVdu2bTV79mwtW7aMW+4BAICkWnDJ7I/UqVNHixYt0qJFi36zT9OmTS+5JPZLPXv21L///e/LrhEAAFz7as1dZgAAAK5CIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKbn4eoCAABA9ev31FpXl1AlUmYOqpZxOUMEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMz6WBaMeOHRowYIBCQ0NlsVj0/vvvO7WXl5dr2rRpCgkJkY+Pj6KionT06FGnPqdPn9aQIUNktVrl7++vuLg4FRYWOvXZv3+/unfvrjp16igsLEyzZs2q7l0DAABXEZcGorNnz6pt27ZatGjRr7bPmjVLCxYs0JIlS7R7927Vq1dP0dHROn/+vNFnyJAhOnjwoFJTU7Vhwwbt2LFDo0ePNtodDof69u2rpk2bKjMzUy+99JKmT5+u1157rdr3DwAAXB08XPnm/fv3V//+/X+1rby8XPPmzdPUqVN19913S5Jef/11BQUF6f3339fgwYN1+PBhpaSkaM+ePerUqZMk6ZVXXtGdd96pl19+WaGhoVq9erWKi4u1YsUKeXl56eabb1ZWVpbmzJnjFJwAAIB51do5RNnZ2bLb7YqKijLW+fn5qUuXLkpPT5ckpaeny9/f3whDkhQVFSU3Nzft3r3b6NOjRw95eXkZfaKjo3XkyBGdOXPmV9+7qKhIDofDaQEAANeuWhuI7Ha7JCkoKMhpfVBQkNFmt9sVGBjo1O7h4aGGDRs69fm1MS5+j19KSkqSn5+fsYSFhV35DgEAgFqr1gYiV5oyZYoKCgqM5cSJE64uCQAAVKNaG4iCg4MlSbm5uU7rc3Nzjbbg4GDl5eU5tV+4cEGnT5926vNrY1z8Hr/k7e0tq9XqtAAAgGtXrQ1E4eHhCg4O1tatW411DodDu3fvls1mkyTZbDbl5+crMzPT6LNt2zaVlZWpS5cuRp8dO3aopKTE6JOamqqWLVuqQYMGNbQ3AACgNnNpICosLFRWVpaysrIk/TyROisrSzk5ObJYLEpISNCzzz6rDz/8UAcOHNDQoUMVGhqqgQMHSpIiIiLUr18/jRo1ShkZGfrss880btw4DR48WKGhoZKkBx98UF5eXoqLi9PBgwe1du1azZ8/X4mJiS7aawAAUNu49Lb7vXv3qlevXsbripAybNgwJScna9KkSTp79qxGjx6t/Px8devWTSkpKapTp46xzerVqzVu3Dj16dNHbm5uio2N1YIFC4x2Pz8/bdmyRfHx8erYsaOuu+46TZs2jVvuAQCAwaWBqGfPniovL//NdovFohkzZmjGjBm/2adhw4Zas2bN775PmzZt9K9//avSdQIAgGtbrZ1DBAAAUFMIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPQIRAAAwPRMFYgWLVqkZs2aqU6dOurSpYsyMjJcXRIAAKgFTBOI1q5dq8TERD399NP64osv1LZtW0VHRysvL8/VpQEAABczTSCaM2eORo0apeHDhysyMlJLlixR3bp1tWLFCleXBgAAXMzD1QXUhOLiYmVmZmrKlCnGOjc3N0VFRSk9Pf2S/kVFRSoqKjJeFxQUSJIcDsdlvW9haWklK649LhSdc3UJVeJyj11lcLxrD473n8Px/vM43rXH5Rzvir7l5eV/3LncBP773/+WSyrftWuX0/qJEyeWd+7c+ZL+Tz/9dLkkFhYWFhYWlmtgOXHixB9mBVOcIbpcU6ZMUWJiovG6rKxMp0+fVkBAgCwWiwsrq1kOh0NhYWE6ceKErFarq8tBNeN4mwvH21zMerzLy8v1448/KjQ09A/7miIQXXfddXJ3d1dubq7T+tzcXAUHB1/S39vbW97e3k7r/P39q7PEWs1qtZrqF8jsON7mwvE2FzMebz8/vz/VzxSTqr28vNSxY0dt3brVWFdWVqatW7fKZrO5sDIAAFAbmOIMkSQlJiZq2LBh6tSpkzp37qx58+bp7NmzGj58uKtLAwAALmaaQDRo0CB9//33mjZtmux2u9q1a6eUlBQFBQW5urRay9vbW08//fQllw9xbeJ4mwvH21w43n/MUl7+Z+5FAwAAuHaZYg4RAADA7yEQAQAA0yMQAQAA0yMQAQAA0yMQ4Telp6fL3d1dMTExri4F1eiRRx6RxWIxloCAAPXr10/79+93dWmoJna7XePHj9cNN9wgb29vhYWFacCAAU7PasPV7+LfbU9PTwUFBemOO+7QihUrVFZW5uryah0CEX7T8uXLNX78eO3YsUMnT550dTmoRv369dOpU6d06tQpbd26VR4eHrrrrrtcXRaqwbFjx9SxY0dt27ZNL730kg4cOKCUlBT16tVL8fHxri4PVazid/vYsWPatGmTevXqpf/93//VXXfdpQsXLri6vFrFNM8hwuUpLCzU2rVrtXfvXtntdiUnJ+tvf/ubq8tCNfH29ja+xiY4OFhPPvmkunfvru+//16NGjVycXWoSo8++qgsFosyMjJUr149Y/3NN9+sESNGuLAyVIeLf7evv/56dejQQV27dlWfPn2UnJyskSNHurjC2oMzRPhV69atU6tWrdSyZUs99NBDWrFihXhklTkUFhbqjTfeUPPmzRUQEODqclCFTp8+rZSUFMXHxzuFoQpm/s5GM+ndu7fatm2rd99919Wl1CoEIvyq5cuX66GHHpL08ynXgoICpaWlubgqVJcNGzbI19dXvr6+ql+/vj788EOtXbtWbm78J+Ja8s0336i8vFytWrVydSlwsVatWunYsWOuLqNW4b92uMSRI0eUkZGhBx54QJLk4eGhQYMGafny5S6uDNWlV69eysrKUlZWljIyMhQdHa3+/fvr+PHjri4NVYizvKhQXl4ui8Xi6jJqFeYQ4RLLly/XhQsXFBoaaqwrLy+Xt7e3Fi5cKD8/PxdWh+pQr149NW/e3Hi9bNky+fn5aenSpXr22WddWBmq0k033SSLxaKvvvrK1aXAxQ4fPqzw8HBXl1GrcIYITi5cuKDXX39ds2fPNs4YZGVlad++fQoNDdWbb77p6hJRAywWi9zc3PTTTz+5uhRUoYYNGyo6OlqLFi3S2bNnL2nPz8+v+aJQ47Zt26YDBw4oNjbW1aXUKpwhgpMNGzbozJkziouLu+RMUGxsrJYvX64xY8a4qDpUl6KiItntdknSmTNntHDhQhUWFmrAgAEurgxVbdGiRbrtttvUuXNnzZgxQ23atNGFCxeUmpqqxYsX6/Dhw64uEVWo4ne7tLRUubm5SklJUVJSku666y4NHTrU1eXVKgQiOFm+fLmioqJ+9bJYbGysZs2apf3796tNmzYuqA7VJSUlRSEhIZKk+vXrq1WrVlq/fr169uzp2sJQ5W644QZ98cUXeu655/T444/r1KlTatSokTp27KjFixe7ujxUsYrfbQ8PDzVo0EBt27bVggULNGzYMG6a+AVLObPsAACAyREPAQCA6RGIAACA6RGIAACA6RGIAACA6RGIAACA6RGIAACA6RGIAACA6RGIAACA6RGIAACA6RGIAACA6RGIAKCalZaWqqyszNVlAPgdBCIAV4WUlBR169ZN/v7+CggI0F133aVvv/1WknTs2DFZLBa9++676tWrl+rWrau2bdsqPT3d2P748eMaMGCAGjRooHr16unmm2/Wxx9/LEnq1KmTXn75ZaPvwIED5enpqcLCQknSd999J4vFom+++UbSz98g/sQTT+j6669XvXr11KVLF23fvt3YPjk5Wf7+/vrwww8VGRkpb29v5eTkVPdHBOAKEIgAXBXOnj2rxMRE7d27V1u3bpWbm5vuuecepzMvf//73/XEE08oKytLLVq00AMPPKALFy5IkuLj41VUVKQdO3bowIEDevHFF+Xr6ytJuv32241AU15ern/961/y9/fXzp07JUlpaWm6/vrr1bx5c0nSuHHjlJ6errfeekv79+/X/fffr379+uno0aNGLefOndOLL76oZcuW6eDBgwoMDKyJjwlAJfFt9wCuSv/v//0/NWrUSAcOHJCvr6/Cw8O1bNkyxcXFSZIOHTqkm2++WYcPH1arVq3Upk0bxcbG6umnn75krI8++kgPP/ywfvjhB3355Zfq16+fBg0apDp16uiFF17QqFGjdO7cOa1evVo5OTm64YYblJOTo9DQUGOMqKgode7cWc8//7ySk5M1fPhwZWVlqW3btjX2mQCoPM4QAbgqHD16VA888IBuuOEGWa1WNWvWTJKcLkW1adPG+DkkJESSlJeXJ0l67LHH9Oyzz+q2227T008/rf379xt9u3fvrh9//FH//ve/lZaWpttvv109e/Y0zhqlpaWpZ8+ekqQDBw6otLRULVq0kK+vr7GkpaUZl/AkycvLy6keALWbh6sLAIA/Y8CAAWratKmWLl2q0NBQlZWV6ZZbblFxcbHRx9PT0/jZYrFIknFJbeTIkYqOjtbGjRu1ZcsWJSUlafbs2Ro/frz8/f3Vtm1bbd++Xenp6brjjjvUo0cPDRo0SF9//bWOHj2q22+/XZJUWFgod3d3ZWZmyt3d3anGiktwkuTj42PUAKD24wwRgFrvhx9+0JEjRzR16lT16dNHEREROnPmzGWPExYWpjFjxujdd9/V448/rqVLlxptt99+uz799FPt2LFDPXv2VMOGDRUREaHnnntOISEhatGihSSpffv2Ki0tVV5enpo3b+60BAcHV9k+A6hZBCIAtV6DBg0UEBCg1157Td988422bdumxMTEyxojISFBmzdvVnZ2tr744gt9+umnioiIMNp79uypzZs3y8PDQ61atTLWrV692jg7JEktWrTQkCFDNHToUL377rvKzs5WRkaGkpKStHHjxqrZYQA1jkAEoNZzc3PTW2+9pczMTN1yyy2aMGGCXnrppcsao7S0VPHx8YqIiFC/fv3UokULvfrqq0Z79+7dVVZW5hR+evbsqdLSUmP+UIWVK1dq6NChevzxx9WyZUsNHDhQe/bsUZMmTa5oPwG4DneZAQAA0+MMEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAML3/D2kCGEOS6WzIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_question = combined_dataset.groupby(['dataset', 'answer'])['correct'].sum()\n",
    "\n",
    "sns.barplot(x='answer', y='correct', hue='dataset', data=df_question.reset_index(), estimator=np.mean, errorbar=('ci', 95), palette='Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eabe8057-3548-4d64-9dfc-f847e31cabbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = df_question.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b10479c-f922-4f87-aae3-1dd3702bd082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mmlu</td>\n",
       "      <td>A</td>\n",
       "      <td>3608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mmlu</td>\n",
       "      <td>B</td>\n",
       "      <td>6264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mmlu</td>\n",
       "      <td>C</td>\n",
       "      <td>7182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mmlu</td>\n",
       "      <td>D</td>\n",
       "      <td>8222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other</td>\n",
       "      <td>A</td>\n",
       "      <td>2458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>other</td>\n",
       "      <td>B</td>\n",
       "      <td>2386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>other</td>\n",
       "      <td>C</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>other</td>\n",
       "      <td>D</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset answer  correct\n",
       "0    mmlu      A     3608\n",
       "1    mmlu      B     6264\n",
       "2    mmlu      C     7182\n",
       "3    mmlu      D     8222\n",
       "4   other      A     2458\n",
       "5   other      B     2386\n",
       "6   other      C     1942\n",
       "7   other      D     1411"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "196136bd-31de-445c-96b4-d77be08a7b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_correct_answers = df_question.pivot(index='dataset', columns='answer', values='correct')\n",
    "\n",
    "\n",
    "array_2d = pivot_correct_answers.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "109fe6c2-7f29-434e-9110-64b999a6b1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>answer</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mmlu</th>\n",
       "      <td>3608</td>\n",
       "      <td>6264</td>\n",
       "      <td>7182</td>\n",
       "      <td>8222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>2458</td>\n",
       "      <td>2386</td>\n",
       "      <td>1942</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "answer      A     B     C     D\n",
       "dataset                        \n",
       "mmlu     3608  6264  7182  8222\n",
       "other    2458  2386  1942  1411"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_correct_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d10b7214-f471-46f5-a159-46ce235a86b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3608, 6264, 7182, 8222],\n",
       "       [2458, 2386, 1942, 1411]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9dc3d9-19c3-4abe-bbfe-bbd19a05c758",
   "metadata": {},
   "source": [
    "The null hypothesis is : The distribution are the same.\n",
    "The alternative hypothesis would be : the distributions are different.\n",
    "\n",
    "So we have to do a two sided test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "92392cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "res = chi2_contingency(array_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "52da73d5-0008-47d3-b91a-b4b593797e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b3305663-78b4-49f0-9b7c-248f9813f4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.dof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8776c444-f74f-4268-b35a-259c5d57fa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can reject the null hypothesis at maximum 100.0% significance\n"
     ]
    }
   ],
   "source": [
    "print(f'We can reject the null hypothesis at maximum {(1 - res.pvalue)*100}% significance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c39b1-e2fb-47be-b9d0-e2d7b1e59a73",
   "metadata": {},
   "source": [
    "So we can't reject the null hypothesis, we should keep looking for another explanation of the data, since 0.05 < pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3125ad-5a7e-44e7-999a-a0ff99855d39",
   "metadata": {},
   "source": [
    "### 2.3 (7 pt)\n",
    "\n",
    "Let's dive in deeper:\n",
    "\n",
    "A. What is language model X's mean accuracy conditioned on the four answer options for each dataset?\n",
    "\n",
    "B. Compare LM X's performance when the correct answer is \"A\" between the two datasets. Use a T-test with CI = 0.95. What do you conclude?\n",
    "\n",
    "C. Compare LM X's performance when the correct answer is \"A\" vs. \"C or D\" for each dataset. Use a T-test with CI = 0.95. What do you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "39097a11-8efe-46d1-8bc3-5587bb58d199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>answer</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mmlu</th>\n",
       "      <td>0.972688</td>\n",
       "      <td>0.799185</td>\n",
       "      <td>0.707905</td>\n",
       "      <td>0.633592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.676407</td>\n",
       "      <td>0.603744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "answer          A         B         C         D\n",
       "dataset                                        \n",
       "mmlu     0.972688  0.799185  0.707905  0.633592\n",
       "other    0.974026  0.806452  0.676407  0.603744"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A\n",
    "combined_dataset[combined_dataset['model_name'] == 'X'].groupby(['dataset', 'answer']).aggregate({'correct' : 'mean'}).reset_index().rename(columns={'correct' : 'mean'}).pivot(index='dataset', columns='answer', values='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ae67c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B\n",
    "performance_mmlu_A = combined_dataset[(combined_dataset['model_name'] == 'X') & \n",
    "                                      (combined_dataset['dataset'] == 'mmlu') & \n",
    "                                      (combined_dataset['answer'] == 'A')]['correct']\n",
    "\n",
    "performance_other_A = combined_dataset[(combined_dataset['model_name'] == 'X') & \n",
    "                                       (combined_dataset['dataset'] == 'other') & \n",
    "                                       (combined_dataset['answer'] == 'A')]['correct']\n",
    "\n",
    "t_stat, p_value = ttest_ind(performance_mmlu_A, performance_other_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4640800-0967-41c7-b5cf-5a1baf9d4598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21059510911432247"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fe1ee776-371e-455e-9435-f5f9169abaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8332191972699248"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ad8343-b2b2-41ed-9083-5fc9a5f9ad8e",
   "metadata": {},
   "source": [
    "p > 0.05 so we can't reject the null hypothesis, we have to keep looking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "636af6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C\n",
    "performance_other_C_or_D = combined_dataset[(combined_dataset['model_name'] == 'X') & \n",
    "                                       (combined_dataset['dataset'] == 'other') & \n",
    "                                       (combined_dataset['answer'].isin(['C', 'D']))]['correct']\n",
    "\n",
    "performance_mmlu_C_or_D = combined_dataset[(combined_dataset['model_name'] == 'X') & \n",
    "                                       (combined_dataset['dataset'] == 'mmlu') & \n",
    "                                       (combined_dataset['answer'].isin(['C', 'D']))]['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "205df7f2-9a84-4454-8c1e-e14a1ec96a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat_other, p_value_other = ttest_ind(performance_other_A, performance_other_C_or_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f7de182e-b03c-491b-9f78-b73a3f553379",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat_mmlu, p_value_mmlu = ttest_ind(performance_mmlu_A, performance_mmlu_C_or_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07a07603-3627-48b0-86d8-da6d3bc8dc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.900859805611251e-96"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ca07fa5-1a31-4327-80e0-58d994bd0a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.334906497224946e-139"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value_mmlu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c3c7c90b-b778-4f40-abfd-e0a36267e95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21059510911432247"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ceb19a-ddba-416a-9b3d-21319fafd35f",
   "metadata": {},
   "source": [
    "p is very small, we have p < 0.05, we can reject the null hypothesis that is the distriubtion of answering A is the same as C or D. Which would mean that the model is biased on answers A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33848ff9-2604-4e48-b5df-3207dc81e9a9",
   "metadata": {},
   "source": [
    "### 2.4 (2 pt)\n",
    "\n",
    "What an intriguing finding! \n",
    "\n",
    "A. Print the mean accuracies conditioned on the correct answer for all LMs for each dataset.\n",
    "\n",
    "B. /Discuss:/ What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ec53ce2c-866e-440a-ac79-7813cb756782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mmlu</th>\n",
       "      <th>X</th>\n",
       "      <td>0.972688</td>\n",
       "      <td>0.799185</td>\n",
       "      <td>0.707905</td>\n",
       "      <td>0.633592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.623836</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.733470</td>\n",
       "      <td>0.904252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>0.643079</td>\n",
       "      <td>0.641182</td>\n",
       "      <td>0.669115</td>\n",
       "      <td>0.661139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">other</th>\n",
       "      <th>X</th>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.676407</td>\n",
       "      <td>0.603744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.625232</td>\n",
       "      <td>0.663978</td>\n",
       "      <td>0.762987</td>\n",
       "      <td>0.920437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>0.680891</td>\n",
       "      <td>0.667563</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>0.677067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "answer                     A         B         C         D\n",
       "dataset model_name                                        \n",
       "mmlu    X           0.972688  0.799185  0.707905  0.633592\n",
       "        Y           0.623836  0.688073  0.733470  0.904252\n",
       "        Z           0.643079  0.641182  0.669115  0.661139\n",
       "other   X           0.974026  0.806452  0.676407  0.603744\n",
       "        Y           0.625232  0.663978  0.762987  0.920437\n",
       "        Z           0.680891  0.667563  0.662338  0.677067"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A\n",
    "model_answer_accuracy = combined_dataset.groupby(['dataset', 'model_name', 'answer']).aggregate({'correct' : 'mean'}).reset_index().rename(columns={'correct' : 'accuracy'})\n",
    "model_answer_accuracy.pivot(index=['dataset','model_name'], columns='answer', values='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce58e47",
   "metadata": {},
   "source": [
    "B. /Discuss:/\n",
    "The model X seems to work very well for question A and B in both dataset, TODO BIASED\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdd9d3c-5a03-4b30-84f7-a7dfbee1373e",
   "metadata": {},
   "source": [
    "### 2.5 (2 pt)\n",
    "\n",
    "Concerned with your findings so far, you quickly consult with Ms. Sakota. After thinking it over, Ms. Sakota concludes that more tests are needed. She orders a second round of MMLU results. However, the clever Ms. Sakota thinks of the following twist: while keeping questions fixed, she randomly permutes the position of the correct answer. The new results can be found in the folder `data/task_2_5/`:\n",
    "```\n",
    "task_2_5/\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ lm_scores_mmlu_shuffle.csv\n",
    "```\n",
    "\n",
    "/Discuss:/ Why would Ms. Sakota do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d073adc-bc7e-4f50-ada7-83e07a452f95",
   "metadata": {},
   "source": [
    "She thinks that maybe the LLms learned that it's better to guess A,B than the other, so she wants to see if the suffle model will guess more on the answers that took the place of A, B in the non shuffle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cc586a",
   "metadata": {},
   "source": [
    "/Discuss:/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9150ae0-dbaa-4c88-bf80-ec03127c6945",
   "metadata": {},
   "source": [
    "### 2.6 (4 pt)\n",
    "\n",
    "Increasingly sceptical of the language models' performance, you read up on proper testing practices. You stumble upon the concept of [test-rested stability](https://en.wikipedia.org/wiki/Repeatability), which roughtly states that:\n",
    "\n",
    "\"_Measurements taken by a single person or instrument on the same item, under the same conditions, and in a short period of time, should have the same results._\"\n",
    "\n",
    "In our case, we would assume an LM would have the same performance on a given question regardless of the correct answer position. One way of testing this is by using the following metric:\n",
    "\n",
    "$$\\text{test-retest metric} = \\frac{1}{N}\\sum_{i=1}^N \\frac{1}{M}\\sum_{j=1}^M c^i_0 c_j^i,$$\n",
    "\n",
    "where $c^i_0 \\in \\{0, 1\\}$ indicates whether the model answers the $i^{\\text{th}}$ question correctly (1 if correct, 0 if incorrect). $c_j^i$ indicates whether the model answers the $i^{\\text{th}}$ question correctly in the $j^{\\text{th}}$ shuffled version of the answer label content. Finally, $M$ is the total number of shuffles and $N$ is the dataset size.\n",
    "\n",
    "Task: compute the test-retest metric for each language model using the original `lm_scores_mmlu.csv` file and the new `lm_scores_mmlu_shuffle.csv` file. Using a bar plot, visualize your results by comparing the accuracy of the original `lm_scores_mmlu.csv` and the test-retest scores.\n",
    "\n",
    "**hints**\n",
    "- what is $M$ in our case?\n",
    "\n",
    "(bonus: no points, but so much sweet, sweet knowledge - check out [the following article](https://arxiv.org/pdf/2406.19470v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f8fa24-58db-4ae6-bb9b-890fa57465a2",
   "metadata": {},
   "source": [
    "In our case we have M = 1 because we only have one shifted version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e25a2182-66f4-4abe-a7fb-d3143fd8d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mmlu_shuffle = pd.read_csv('ada-2024-homework-1-5ds//task_2_5/lm_scores_mmlu_shuffle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4d1171f0-616d-4988-ad31-6fb2a0234a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_retest_metric = np.mean(df_mmlu_shuffle['correct']*df_mmlu['correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "86cce1a0-b3eb-4001-ab4a-0bbd86f946c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test retest metric is 0.5338862289101687\n"
     ]
    }
   ],
   "source": [
    "print(f'The test retest metric is {test_retest_metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70bee6e-0c81-4f5a-b1a8-16a96aa2ae17",
   "metadata": {},
   "source": [
    "### 2.7 (2 pt)\n",
    "\n",
    "A. Using the unshuffled data: For each LM, print the distribution of the answers they give as well as the accuracy conditioned on the answer they give.\n",
    "\n",
    "B. /Discuss:/ Describe what you observe\n",
    "\n",
    "[bonus: not scored, but again _that sweet, sweet knowledge_] Could you think of a plausible explanation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4956581b-d047-46cb-ae71-1508a9a0b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A\n",
    "df_mmlu_stats = df_mmlu.groupby(['model_name', 'result']).agg(\n",
    "    distribution=('result', 'count'),  # Count the occurrences of each result\n",
    "    accuracy=('correct', 'mean')       # Calculate the mean accuracy\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "total_count = df_mmlu_stats.groupby('model_name')['distribution'].transform('sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7eede7bd-c82a-4ccd-bcbc-69a41764ef07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"4\" halign=\"left\">distribution</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.367927</td>\n",
       "      <td>0.884543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4259.0</td>\n",
       "      <td>2659.0</td>\n",
       "      <td>2409.0</td>\n",
       "      <td>2369.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.897606</td>\n",
       "      <td>0.827861</td>\n",
       "      <td>0.631608</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>2256.0</td>\n",
       "      <td>3015.0</td>\n",
       "      <td>5353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>0.476103</td>\n",
       "      <td>0.654073</td>\n",
       "      <td>0.703429</td>\n",
       "      <td>0.727487</td>\n",
       "      <td>2176.0</td>\n",
       "      <td>2885.0</td>\n",
       "      <td>3237.0</td>\n",
       "      <td>3398.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy                               distribution          \\\n",
       "result             A         B         C         D            A       B   \n",
       "model_name                                                                \n",
       "X           0.367927  0.884543  1.000000  1.000000       4259.0  2659.0   \n",
       "Y           0.937500  0.897606  0.827861  0.631608       1072.0  2256.0   \n",
       "Z           0.476103  0.654073  0.703429  0.727487       2176.0  2885.0   \n",
       "\n",
       "                            \n",
       "result           C       D  \n",
       "model_name                  \n",
       "X           2409.0  2369.0  \n",
       "Y           3015.0  5353.0  \n",
       "Z           3237.0  3398.0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mmlu_stats.pivot(index= 'model_name', columns='result', values=['accuracy', 'distribution'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65639228",
   "metadata": {},
   "source": [
    "B. /Discuss:/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3186fe-ef8e-4af3-9a07-a6081d454e5a",
   "metadata": {},
   "source": [
    "## Task 3 (16 points): What do Questions and Answers look like for a Language Model?\n",
    "\n",
    "While you feel pretty good about the tests you conducted so far, something still bothers you: what if the language models don't see the data like you do? Suddenly, you receive a phone call from a wise AI sage in the West, _Westoda_:\n",
    "\n",
    "```\n",
    "\"Hmm, correct you are, young padawan, to question how the world is seen by large language models! Simple 'text' it is not, hmm? No, no, no! Characters and words, the way of puny humans, this is not, heh heh heh.\n",
    "\n",
    "'Tokens', they use, yes! Mysterious and powerful, these tokens are. Expand our vocabulary, they do, beyond the simple 'a to Z'. Chunky blocks of text, they become, yes! 'Hello world', a simple phrase it may seem. But to a language model, '[24912, 2375]' it might appear, yes! Confusing, it is, hmm?\n",
    "\n",
    "Wise, it would be, to explore these MMLU data points through the eyes of a language model, you think? Yes, yes! Much to learn, there is. The ways of the tokens, understand you must, if truly comprehend the great LMs, you wish to.\n",
    "Meditate on this, you should. The force of natural language processing, strong it is. But patience, you must have, my young padawan. For only through great study and contemplation, will the mysteries of the tokens reveal themselves to you, they will. Yes, hmmm!\"\n",
    "```\n",
    "\n",
    "Admittingly, Westoda at times speaks in riddles‚Ä¶ However, he was explaining a crucial aspect of modern LMs called [Tokenization](https://learn.microsoft.com/en-us/dotnet/ai/conceptual/understanding-tokens):\n",
    "\n",
    "\n",
    "‚ÄúTokens are words, character sets, or combinations of words and punctuation that are used by [language models (LMs)] to decompose text into. Tokenization is the first step in training‚Äù\n",
    "\n",
    "Instead of characters, LMs process natural language using ‚Äútokens‚Äù. While this is useful for a number of reasons, it does at times introduce some ‚Äúunintuitive‚Äù behavior‚Ä¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e2c66517-938b-4331-9eea-1b23fe4ad9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humans see: \"hello world\" --> language models see: [24912, 2375]\n"
     ]
    }
   ],
   "source": [
    "# PROVIDED CODE\n",
    "\n",
    "try:\n",
    "    import tiktoken\n",
    "except Exception as e:\n",
    "    print('installing tiktoken package')\n",
    "    \n",
    "    !pip install tiktoken\n",
    "    \n",
    "    import tiktoken\n",
    "\n",
    "def tokenize_text(s):\n",
    "    enc = tiktoken.encoding_for_model('gpt-4o')\n",
    "    tokens = enc.encode(str(s))\n",
    "    return tokens\n",
    "\n",
    "example_string = 'hello world'\n",
    "print(f'humans see: \"{example_string}\" --> language models see: {tokenize_text(example_string)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8019ee-7d52-496f-afff-c96f2f9db08c",
   "metadata": {},
   "source": [
    "### 3.1 (5 pt)\n",
    "\n",
    "Use the provided code in the cell above to \"see the world through the eyes of a language model\":\n",
    "\n",
    "A. Tokenize the questions of the original MMLU data provided in task 1: `task_1/mmlu_data/test.csv` and plot the token distribution (the frequency of each token).\n",
    "\n",
    "B. Same as (A), but now for the answers in columns (columns \"A\", \"B\", \"C\", and \"D\").\n",
    "\n",
    "C. Isolate the tokens for the strings \"A\", \"B\", \"C\", and \"D\", then, for their occurances in both questions and answers, print their relative distribution to each other.\n",
    "\n",
    "**hint**\n",
    "- There are a _lot_ of tokens, consider using a cutoff point and log scale\n",
    "- For (c), they should sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f9e30f10-aaef-4b0f-a6f0-84d6d156ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A\n",
    "cutoff_frequency = 10000\n",
    "tokens = df_test['question'].apply(tokenize_text).explode()\n",
    "frequency = tokens.value_counts(normalize = True).head(cutoff_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fa563ecb-7003-4c96-ae93-dbb8c4ed7573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(frequency, bins=100, kde=False)\n",
    "plt.xlim(0, 200000)\n",
    "plt.yscale('log')\n",
    "plt.title('Token Frequency Distribution')\n",
    "plt.xlabel('Token')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fe1f8be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# B\n",
    "tokens_A = df_test['A'].apply(tokenize_text).explode()\n",
    "tokens_B = df_test['B'].apply(tokenize_text).explode()\n",
    "tokens_C = df_test['C'].apply(tokenize_text).explode()\n",
    "tokens_D = df_test['D'].apply(tokenize_text).explode()\n",
    "\n",
    "\n",
    "combined_tokens = (list(tokens_A) + list(tokens_B) + list(tokens_C)+ list(tokens_D))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(combined_tokens, bins=100, kde=False)\n",
    "plt.xlim(0, 200000)\n",
    "plt.yscale('log')\n",
    "plt.title('Token Frequency Distribution across answers A B C and D')\n",
    "plt.xlabel('Token')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "feca57f3-6ae4-46d8-8aa6-cac5cd782dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(list(combined_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cd392df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A has a distribution of 0.7916865742952699\n",
      "B has a distribution of 0.06020066889632107\n",
      "C has a distribution of 0.10152890587673197\n",
      "D has a distribution of 0.046583850931677016\n"
     ]
    }
   ],
   "source": [
    "# C\n",
    "token_A = tokenize_text(\"A\")[0]\n",
    "token_B = tokenize_text(\"B\")[0]\n",
    "token_C = tokenize_text(\"C\")[0]\n",
    "token_D = tokenize_text(\"D\")[0]\n",
    "\n",
    "combined_tokens_answers_questions = list(tokens) + combined_tokens\n",
    "\n",
    "occurence_A = combined_tokens_answers_questions.count(token_A)\n",
    "occurence_B = combined_tokens_answers_questions.count(token_B)\n",
    "occurence_C = combined_tokens_answers_questions.count(token_C)\n",
    "occurence_D = combined_tokens_answers_questions.count(token_D)\n",
    "\n",
    "total_occurences = occurence_A + occurence_B + occurence_C + occurence_D\n",
    "\n",
    "print(f'A has a distribution of {occurence_A/total_occurences}')\n",
    "print(f'B has a distribution of {occurence_B/total_occurences}')\n",
    "print(f'C has a distribution of {occurence_C/total_occurences}')\n",
    "print(f'D has a distribution of {occurence_D/total_occurences}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a674929c-68e1-4cd8-97b3-efa0cdae4874",
   "metadata": {},
   "source": [
    "### 3.2 (3 pt)\n",
    "\n",
    "What if the number of \"A\", \"B\", \"C\", and \"D\" tokens in the question and answer pairs could influence a language model's decisions?\n",
    "\n",
    "A. For each combined question-answers pair, compute: \n",
    "1. the number of \"A\", \"B\", \"C\", and \"D\" tokens; and\n",
    "2. the total number of tokens.\n",
    "3. then, group by the \"correct\" answer and compute the mean frequency of A, B, C, and D tokens and the total number of tokens. \n",
    "4. finally, print your results\n",
    "\n",
    "B. /Discuss:/ What do you think of the hypothesis that the frequency of A, B, C, and D tokens could influence answers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "59806c78-9a5d-4f89-a69b-b2113b498c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "      <th>subject</th>\n",
       "      <th>question_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find the degree for the given field extension ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  A  B  C  D answer  \\\n",
       "0  Find the degree for the given field extension ...  0  4  2  6      B   \n",
       "\n",
       "            subject  question_id  \n",
       "0  abstract algebra            0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "581ab7d2-4c3a-4734-ba47-c8ffea61b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['tokens'] = df_test['A'].apply(tokenize_text)+df_test['B'].apply(tokenize_text)+df_test['C'].apply(tokenize_text)+df_test['D'].apply(tokenize_text)+df_test['question'].apply(tokenize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9e7924dd-d591-4123-9666-7c7185e38475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question', 'A', 'B', 'C', 'D', 'answer', 'subject', 'question_id',\n",
       "       'tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "85f40a89-0d41-43bf-8519-f73804de8a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['total_token_number'] = df_test['tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "25419cc1-f058-4c51-a0aa-577272b8b578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A\n",
    "df_test['token_A'] = df_test['tokens'].apply(lambda x : x.count(token_A))\n",
    "df_test['token_B'] = df_test['tokens'].apply(lambda x : x.count(token_B))\n",
    "df_test['token_C'] = df_test['tokens'].apply(lambda x : x.count(token_C))\n",
    "df_test['token_D'] = df_test['tokens'].apply(lambda x : x.count(token_D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5b743167-433a-421d-955f-420109787c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency_A</th>\n",
       "      <th>frequency_B</th>\n",
       "      <th>frequency_C</th>\n",
       "      <th>frequency_D</th>\n",
       "      <th>mean_token_number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.243017</td>\n",
       "      <td>0.018932</td>\n",
       "      <td>0.025140</td>\n",
       "      <td>0.013035</td>\n",
       "      <td>93.187151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.231947</td>\n",
       "      <td>0.019642</td>\n",
       "      <td>0.029463</td>\n",
       "      <td>0.012709</td>\n",
       "      <td>88.846332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.226410</td>\n",
       "      <td>0.018984</td>\n",
       "      <td>0.034897</td>\n",
       "      <td>0.015355</td>\n",
       "      <td>92.653825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.242850</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>0.030985</td>\n",
       "      <td>0.014301</td>\n",
       "      <td>92.110169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        frequency_A  frequency_B  frequency_C  frequency_D  mean_token_number\n",
       "answer                                                                       \n",
       "A          0.243017     0.018932     0.025140     0.013035          93.187151\n",
       "B          0.231947     0.019642     0.029463     0.012709          88.846332\n",
       "C          0.226410     0.018984     0.034897     0.015355          92.653825\n",
       "D          0.242850     0.014566     0.030985     0.014301          92.110169"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby('answer').agg(frequency_A=('token_A', 'mean'),frequency_B=('token_B', 'mean'),frequency_C=('token_C', 'mean'),frequency_D=('token_D', 'mean'),mean_token_number=('total_token_number', 'mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea8a279",
   "metadata": {},
   "source": [
    "B. /Discuss:/\n",
    "It doesn't seem like it because every tokens have almost the same frequency in each answer cases, so it doesn't seem like influencing the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af25ef95-d2ce-4112-87f7-8b0a52755e2a",
   "metadata": {},
   "source": [
    "### 3.3 (4 pt)\n",
    "\n",
    "Three of the most important considerations when deciding between language models are:\n",
    "\n",
    "Quality\n",
    "Costs\n",
    "Speed\n",
    "\n",
    "So far, much of your analysis has focused on quality. However, the government has indicated that they are quite concerned about both the total costs and speed as well. Specifically, it has been brought to their attention that a new `turbo` model has been launched! \n",
    "\n",
    "This model is both cheaper and faster than the models you evaluated so far. However, there is a catch: the context length* is much smaller than that of the other LMS. Namely, it can only process **300** tokens during inference. Meanwhile, the other models can process up to 100K tokens! \n",
    "\n",
    "*_The ‚Äúcontext length‚Äù refers to the number of tokens that can be given to an LM as input._\n",
    "\n",
    "A. Are there subjects where using the cheaper model might be problematic? I.e., where part of the question and answer(s) might not fit completely in the context?\n",
    "\n",
    "B. /Discuss:/ Can you think of a strategy that would balance the needs of the government?\n",
    "\n",
    "**hint**:\n",
    "- An LM needs to have both the question and the different answer options in its context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a88a6fa3-2735-44d7-9944-076cc9f679ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A\n",
    "max_subject_token = df_test.groupby('subject').agg(max_token_number = ('total_token_number', 'max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "afcd7cb0-7175-41e4-aabb-8c9e30e8aa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_subject = max_subject_token[max_subject_token['max_token_number'] > 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4aa8b3a5-7a22-4d7b-9ae8-46440d4c1bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It would be problematic for this subject : college medicine\n",
      "It would be problematic for this subject : high school computer science\n",
      "It would be problematic for this subject : high school european history\n",
      "It would be problematic for this subject : high school statistics\n",
      "It would be problematic for this subject : high school us history\n",
      "It would be problematic for this subject : high school world history\n",
      "It would be problematic for this subject : professional law\n",
      "It would be problematic for this subject : professional medicine\n",
      "It would be problematic for this subject : security studies\n",
      "It would be problematic for this subject : virology\n"
     ]
    }
   ],
   "source": [
    "for subject in problematic_subject.index : \n",
    "    print(f'It would be problematic for this subject : {subject}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f8a44a",
   "metadata": {},
   "source": [
    "B. /Dicsuss:/\n",
    "We could use a combination of several models, if the tokens are less than 300 use the faster model else use another model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f07bf-558f-467c-8f66-d88db561d455",
   "metadata": {},
   "source": [
    "### 3.4 (4 pt)\n",
    "\n",
    "/Discuss:/ The time has come to give your final recommendation on the use of LMs in education to the government! Taking into account everything you analyzed in all the preceding tasks (1, 2, and 3), please write a short recommendation consisting of 4 bullet points discussing your concerns.\n",
    "\n",
    "**hint**\n",
    "- Try to use the MECE framework: _Mutually Exclusive Collectively Exhaustive_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a5fa5",
   "metadata": {},
   "source": [
    "/Discuss:/\n",
    "1. \n",
    "\n",
    "2. \n",
    "\n",
    "3. \n",
    "\n",
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817f3f7-2dbd-453f-88ff-6b977b9f9acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
